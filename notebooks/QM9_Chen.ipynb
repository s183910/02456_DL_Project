{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.datasets import QM9\n",
    "\n",
    "class PaiNNDataset(Dataset):\n",
    "    \"\"\" Class for dataset from QM9 data folder \"\"\"\n",
    "\n",
    "    def __init__(self, r_cut: float, path: str, self_edge: bool = False):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            path: file path for the dataset\n",
    "        \"\"\"\n",
    "        self.data = QM9(root = path)\n",
    "        self.r_cut = r_cut\n",
    "        self.self_edge = self_edge\n",
    "\n",
    "    def add_edges(self, pos) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\" Return the edges between the atoms based on r_cut (adjacency matrix) \"\"\"\n",
    "        n_atoms = pos.shape[0]\n",
    "\n",
    "        # Finding each edge and adding the coordinates to the list\n",
    "        edges_coord = []\n",
    "        dist = []\n",
    "        normalized = []\n",
    "        for i in range(n_atoms):\n",
    "            for j in range(i + 1):\n",
    "                if i==j and self.self_edge:\n",
    "                    edges_coord.append([i,j])\n",
    "\n",
    "                diff = pos[j] - pos[i]  \n",
    "                dist_ij = torch.linalg.norm(diff)\n",
    "                if dist_ij <= self.r_cut and i!=j:\n",
    "                    edges_coord.append([i,j])\n",
    "                    edges_coord.append([j,i])\n",
    "                    dist.append(dist_ij.item())\n",
    "                    dist.append(dist_ij.item())    # Same distance ij or ji\n",
    "                    normalized.append((diff/dist_ij).tolist())\n",
    "                    normalized.append((-diff/dist_ij).tolist())\n",
    "\n",
    "        return torch.tensor(edges_coord), torch.tensor(dist).unsqueeze(dim=-1), torch.tensor(normalized)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the length of the dataset \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> torch.Tensor:\n",
    "        \"\"\" Return the sample corresponding to idx \"\"\"\n",
    "        # Add the adjacency matrix\n",
    "        edges_coord, dist, normalized = self.add_edges(self.data[idx]['pos'])\n",
    "        mol = self.data[idx].clone().detach()\n",
    "\n",
    "        # The last N columns (where N is the number of columns) will be the adjacency matrix    \n",
    "        return {'z': mol['z'], 'pos': mol['pos'], 'coord_edges': edges_coord, 'edges_dist': dist, 'normalized': normalized, 'targets': mol['y'], 'n_atom':  mol['z'].shape[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "class PaiNNDataLoader(DataLoader):\n",
    "    \"\"\" PaiNNDataLoader to load PaiNN training data \"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str = \"data\", batch_size: int = 50, r_cut: float = 5., self_edge: bool = False, test_split: float = 0.1, validation_split: float = 0.2, nworkers: int = 2):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            train_path: path to the training dataset\n",
    "            test_path: path to the test dataset(s)\n",
    "            batch_size: size of the batch\n",
    "            shuffle: shuffles the data \n",
    "            test_split: decimal for the split of the test (on the entire dataset)\n",
    "            validation_split: decimal for the split of the validation (on the training dataset)\n",
    "            nworkers: workers for the dataloader class\n",
    "        \"\"\"    \n",
    "        self.r_cut = r_cut\n",
    "        self.dataset = PaiNNDataset(path = data_path, r_cut = r_cut, self_edge = self_edge)\n",
    "        self.length = len(self.dataset)\n",
    "        self.train_sampler = SubsetRandomSampler(np.array(range(self.length)))\n",
    "        self.valid_sampler = None\n",
    "        self.test_sampler = None\n",
    "\n",
    "        if test_split:\n",
    "            self.test_sampler = self._split(test_split)\n",
    "\n",
    "        if validation_split:\n",
    "            self.valid_sampler = self._split(validation_split)\n",
    "\n",
    "        self.init_kwargs = {\n",
    "            'batch_size': batch_size,\n",
    "            'num_workers': nworkers\n",
    "        }\n",
    "\n",
    "        # Return the training dataset\n",
    "        super().__init__(self.dataset, sampler=self.train_sampler, collate_fn=self.collate_fn, **self.init_kwargs)\n",
    "\n",
    "    # We need to define our custom collate_fn because our samples (molecule) have different size\n",
    "    # ie. you cannot use torch.stack on it\n",
    "    def collate_fn(self, data):\n",
    "        \"\"\" Handle how we stack a batch\n",
    "        Args:\n",
    "            data: the data before we output the batch (a tuple containing the dictionary for each molecule)\n",
    "        \"\"\"\n",
    "        # Each mol is a dic with \"z\" = n_atoms here we get a dic with \"z\" = (n_mol, n_atoms_mol)\n",
    "        batch_dict = {k: [dic[k] for dic in data] for k in data[0].keys()} \n",
    "\n",
    "        # We need to define the id and the edges_coord differently (because we begin indexing from 0)\n",
    "        n_atoms = torch.tensor(batch_dict[\"n_atom\"])\n",
    "        \n",
    "        # Converting the n_atom into unique id\n",
    "        ids = torch.repeat_interleave(torch.tensor(range(len(batch_dict['n_atom']))), n_atoms)\n",
    "        # Adding the offset to the neighbours coordinate\n",
    "        edges_coord = torch.cumsum(torch.cat((torch.tensor([0]), n_atoms[:-1])), dim=0)\n",
    "        neighbours = torch.tensor([local_neigh.shape[0] for local_neigh in batch_dict['coord_edges']])\n",
    "        edges_coord = torch.cat([torch.repeat_interleave(edges_coord, neighbours).unsqueeze(dim=1), torch.repeat_interleave(edges_coord, neighbours).unsqueeze(dim=1)], dim=1)\n",
    "        edges_coord += torch.cat(batch_dict['coord_edges'])\n",
    "\n",
    "        return {'z': torch.cat(batch_dict['z']), 'pos': torch.cat(batch_dict['pos']), 'graph': edges_coord, 'edges_dist': torch.cat(batch_dict['edges_dist']), 'normalized': torch.cat(batch_dict['normalized']), 'graph_idx': ids, 'targets': torch.cat(batch_dict['targets'])}\n",
    "\n",
    "    def _split(self, validation_split: float):\n",
    "        \"\"\" Creates a sampler to extract training and validation data\n",
    "        Args:\n",
    "            validation_split: decimal for the split of the validation\n",
    "        \"\"\"    \n",
    "        train_idx = np.array(range(self.length))\n",
    "\n",
    "        # Getting randomly the index of the validation split (we therefore don't need to shuffle)\n",
    "        split_idx = np.random.choice(\n",
    "            train_idx, \n",
    "            int(self.length*validation_split), \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # Deleting the corresponding index in the training set\n",
    "        train_idx = np.delete(train_idx, split_idx)\n",
    "\n",
    "        # Getting the corresponding PyTorch samplers\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        self.train_sampler = train_sampler\n",
    "\n",
    "        return SubsetRandomSampler(split_idx)\n",
    "\n",
    "    def get_val(self) -> list:\n",
    "        \"\"\" Return the validation data\"\"\"\n",
    "        if self.valid_sampler is None:\n",
    "            return None\n",
    "        else: \n",
    "            return DataLoader(self.dataset, sampler=self.valid_sampler, collate_fn=self.collate_fn, **self.init_kwargs)\n",
    "\n",
    "    def get_test(self) -> list:\n",
    "        \"\"\" Return the test data\"\"\"\n",
    "        if self.test_sampler is None:\n",
    "            return None\n",
    "        else: \n",
    "            return DataLoader(self.dataset, sampler=self.test_sampler, collate_fn=self.collate_fn, **self.init_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def rbf(inputs: torch.Tensor, r_cut: float, output_size: int = 20):\n",
    "    \"\"\" Function\n",
    "    Args:\n",
    "        inputs: input to which we apply the rbf (usually it will be distances)\n",
    "        r_cut: the radius at which we cut off\n",
    "    \"\"\"\n",
    "    \n",
    "    # We will apply it between 1 and output size (usually 1 and 20)\n",
    "    n = torch.arange(1, output_size + 1).to(inputs.device)\n",
    "\n",
    "    return torch.sin(n * torch.pi * inputs / (r_cut * inputs))\n",
    "\n",
    "def cos_cut(inputs: torch.Tensor, r_cut: float):\n",
    "    \"\"\" Function\n",
    "    Args:\n",
    "        inputs: inputs on which we will apply Behler-style cosine cutoff\n",
    "    \"\"\"\n",
    "\n",
    "    # We return the cosine cutoff for inputs smaller than the radius cutoff\n",
    "    return 0.5 * (1 + torch.cos(torch.pi * inputs / r_cut)) * (inputs < r_cut).float()\n",
    "\n",
    "def mse(preds: torch.Tensor, targets: torch.Tensor):\n",
    "    return torch.mean((preds - targets).square())\n",
    "\n",
    "def mae(preds: torch.Tensor, targets: torch.Tensor):\n",
    "    return torch.mean(torch.abs(preds - targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/molnet_publish/qm9.zip\n",
      "Extracting data\\raw\\qm9.zip\n",
      "Downloading https://ndownloader.figshare.com/files/3195404\n",
      "Processing...\n",
      "100%|██████████| 133885/133885 [06:38<00:00, 335.82it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "\n",
    "class PaiNNModel(nn.Module):\n",
    "    \"\"\" PaiNN model architecture \"\"\"\n",
    "\n",
    "    def __init__(self, r_cut: float, n_iterations: int = 3, node_size: int = 128, rbf_size: int = 20, device: torch.device = 'cpu'):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            node_size: size of the embedding features\n",
    "        \"\"\"\n",
    "        # Instantiate as a module of PyTorch\n",
    "        super(PaiNNModel, self).__init__()\n",
    "\n",
    "        # Parameters of the model\n",
    "        self.r_cut = r_cut\n",
    "        self.rbf_size = rbf_size\n",
    "        num_embedding = 119 # number of all elements in the periodic table\n",
    "        self.node_size = node_size\n",
    "        self.device = device\n",
    "\n",
    "        # Embedding layer for our model\n",
    "        self.embedding_layer = nn.Embedding(num_embedding, self.node_size)\n",
    "\n",
    "        # Creating the instances for the iterations of message passing and updating\n",
    "        self.message_blocks = nn.ModuleList([Message(node_size=self.node_size, rbf_size=self.rbf_size, r_cut=self.r_cut) for _ in range(n_iterations)])\n",
    "        self.update_blocks = nn.ModuleList([Update(node_size=self.node_size) for _ in range(n_iterations)])\n",
    "    \n",
    "        self.output_layers = nn.Sequential(\n",
    "            nn.Linear(node_size, node_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(node_size, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\" Forward pass logic \n",
    "        Args:\n",
    "            input: dictionnary coming from data_loader\n",
    "        \"\"\"\n",
    "        # Every input into device\n",
    "        graph = input['graph'].to(self.device)\n",
    "        edges_dist = input['edges_dist'].to(self.device)\n",
    "        edges_sense = input['normalized'].to(self.device)\n",
    "        graph_idx = input['graph_idx'].to(self.device)\n",
    "        atomic = input['z'].to(self.device)\n",
    "\n",
    "        # Outputs from the atomic numbers\n",
    "        node_scalars = self.embedding_layer(atomic)\n",
    "\n",
    "        # Initializing the node vector\n",
    "        node_vectors = torch.zeros((graph_idx.shape[0], 3, self.node_size), \n",
    "                                  device = edges_dist.device, \n",
    "                                  dtype = edges_dist.dtype\n",
    "                                  ).to(self.device)\n",
    "        \n",
    "        for message_block, update_block in zip(self.message_blocks, self.update_blocks):\n",
    "            node_scalars, node_vectors = message_block(\n",
    "                node_scalars = node_scalars,\n",
    "                node_vectors = node_vectors,\n",
    "                graph = graph,\n",
    "                edges_dist = edges_dist,\n",
    "                edges_sense = edges_sense\n",
    "            )\n",
    "            node_scalars, node_vectors = update_block(\n",
    "                node_scalars = node_scalars,\n",
    "                node_vectors = node_vectors\n",
    "            )\n",
    "\n",
    "        layer_outputs = self.output_layers(node_scalars)\n",
    "        outputs = torch.zeros_like(torch.unique(graph_idx)).float().unsqueeze(dim=1)\n",
    "\n",
    "        outputs.index_add_(0, graph_idx, layer_outputs)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class Message(nn.Module):\n",
    "    \"\"\" Message block from PaiNN paper\"\"\"\n",
    "    def __init__(self, node_size: int, rbf_size: int, r_cut: float):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            node_size: size to use in the atomwise layers (node_size to 3*node_size)\n",
    "            rbf_size: number of radial basis functions to use in RBF\n",
    "            r_cut: radius to cutoff interaction\n",
    "        \"\"\"\n",
    "        super(Message, self).__init__()\n",
    "        # Atomwise layers applied to node scalars\n",
    "        self.atomwise_layers = nn.Sequential(\n",
    "            nn.Linear(node_size, node_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(node_size, 3 * node_size)\n",
    "        )\n",
    "        \n",
    "        # RBF and cosine cutoff parameters\n",
    "        self.rbf_dim = rbf_size\n",
    "        self.r_cut = r_cut\n",
    "        # rotationally-invariant filters\n",
    "        self.expand_layer = nn.Linear(self.rbf_dim, 384)\n",
    "\n",
    "    def forward(self, node_scalars: torch.Tensor, node_vectors: torch.Tensor, graph: torch.Tensor, edges_dist: torch.Tensor, edges_sense: torch.Tensor):\n",
    "        \"\"\" Forward pass\n",
    "        Args:\n",
    "            node_scalars: scalar representations of the atoms \n",
    "            node_vectors: vector (equivariant) representations of the atoms\n",
    "            graph: interactions between atoms (base on r_cut)\n",
    "            edges_dist: distances between neighbours\n",
    "            r_cut: radius to cutoff interaction\n",
    "        \"\"\"\n",
    "        # Outputs from scalar representations \n",
    "        atomwise_rep = self.atomwise_layers(node_scalars)\n",
    "\n",
    "        # Outputs from edges distances\n",
    "        filter_rbf = rbf(edges_dist, \n",
    "                          r_cut = self.r_cut,\n",
    "                          output_size = self.rbf_dim\n",
    "                          )\n",
    "        filter_out = self.expand_layer(filter_rbf)\n",
    "        cosine_cutoff = cos_cut(edges_dist,\n",
    "                                r_cut = self.r_cut\n",
    "                                )\n",
    "        dist_rep = filter_out * cosine_cutoff\n",
    "\n",
    "        # Getting the Hadamard product by selecting the neighbouring atoms\n",
    "        residual = atomwise_rep[graph[:,1]] * dist_rep\n",
    "\n",
    "        # Splitting the output\n",
    "        residual_vectors, residual_scalars, direction_rep = residual.split(128, dim=-1)\n",
    "\n",
    "        # Hadamard product with the neighbours vectors representation\n",
    "        residual_vectors = node_vectors[graph[:, 1]] * residual_vectors.unsqueeze(dim=1)\n",
    "        # Hadamard product between the direction representations and the sense of the edges\n",
    "        residual_directions = edges_sense.unsqueeze(dim=-1) * direction_rep.unsqueeze(dim=1)\n",
    "        residual_vectors = residual_vectors + residual_directions\n",
    "\n",
    "        node_scalars = node_scalars + torch.zeros_like(node_scalars).index_add_(0, graph[:, 0], residual_scalars)\n",
    "        node_vectors = node_vectors + torch.zeros_like(node_vectors).index_add_(0, graph[:, 0], residual_vectors)\n",
    "\n",
    "        return node_scalars, node_vectors\n",
    "    \n",
    "class Update(nn.Module):\n",
    "    \"\"\" Message block from PaiNN paper\"\"\"\n",
    "    def __init__(self, node_size: int):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            node_size: size to use in the atomwise layers (node_size to 3*node_size)\n",
    "            rbf_size: number of radial basis functions to use in RBF\n",
    "            r_cut: radius to cutoff interaction\n",
    "        \"\"\"\n",
    "        super(Update, self).__init__()\n",
    "        self.node_size = node_size\n",
    "\n",
    "        # U and V matrices \n",
    "        self.U = nn.Linear(node_size, node_size, bias = False)\n",
    "        self.V = nn.Linear(node_size, node_size, bias = False)\n",
    "        \n",
    "        # Atomwise layers applied to node scalars and V projections (stacked)\n",
    "        self.atomwise_layers = nn.Sequential(\n",
    "            nn.Linear(2 * node_size, node_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(node_size, 3 * node_size)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, node_scalars: torch.Tensor, node_vectors: torch.Tensor):\n",
    "        \"\"\" Forward pass\n",
    "        Args:\n",
    "            node_scalars: scalar representations of the atoms \n",
    "            node_vectors: vector (equivariant) representations of the atoms\n",
    "            graph: interactions between atoms (base on r_cut)\n",
    "            edges_dist: distances between neighbours\n",
    "            r_cut: radius to cutoff interaction\n",
    "        \"\"\"\n",
    "        # Outputs from matrix projection\n",
    "        Uv = self.U(node_vectors)\n",
    "        Vv = self.V(node_vectors)\n",
    "\n",
    "        # Stacking V projections and node scalars\n",
    "        node_scalars_Vv = torch.cat((node_scalars, torch.linalg.norm(Vv, dim=1)), dim=1)\n",
    "        a = self.atomwise_layers(node_scalars_Vv)\n",
    "        avv, asv, ass = a.split(self.node_size, dim=-1)\n",
    "\n",
    "        # Scalar product between Uv and Vv\n",
    "        scalar_product = torch.sum(Uv * Vv, dim=1)\n",
    "\n",
    "        # Calculating the residual values for scalars and vectors\n",
    "        residual_scalars = ass + asv * scalar_product\n",
    "        residual_vectors = avv.unsqueeze(dim=1) * Uv\n",
    "\n",
    "        # Updating the representations\n",
    "        node_scalars = node_scalars + residual_scalars\n",
    "        node_vectors = node_vectors + residual_vectors\n",
    "\n",
    "        return node_scalars, node_vectors\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    train_set = PaiNNDataLoader(batch_size=2)\n",
    "    model = PaiNNModel(r_cut = getattr(train_set, 'r_cut'))\n",
    "    val_set = train_set.get_val()\n",
    "    test_set = train_set.get_test()\n",
    "    for i, batch in enumerate(train_set):\n",
    "        output = model(batch)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\" Responsible for training loop and validation \"\"\"\n",
    "    \n",
    "    def __init__(self, model: torch.nn.Module, loss: any, target: int, optimizer: torch.optim, data_loader, scheduler: torch.optim, device: torch.device = \"cpu\"):\n",
    "        \"\"\" Constructor\n",
    "        Args:   \n",
    "            model: Model to use (usually PaiNN)\n",
    "            loss: loss function to use during traning\n",
    "            target: the index of the target we want to predict \n",
    "            optimizer: optimizer to use during training\n",
    "            data_loader: DataLoader object containing train/val/test sets\n",
    "            device: device on which to execute the training\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.target = target\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "\n",
    "        self.train_set = data_loader\n",
    "        self.valid_set = data_loader.get_val()\n",
    "        self.test_set = data_loader.get_test()\n",
    "        self.learning_curve = []\n",
    "        self.valid_perf= []\n",
    "        self.learning_rates = []\n",
    "        self.summaries, self.summaries_axes = plt.subplots(1,3, figsize=(10,5))\n",
    "\n",
    "\n",
    "    def _train_epoch(self) -> dict:\n",
    "        \"\"\" Training logic for an epoch\n",
    "        \"\"\"\n",
    "        for batch_idx, batch in enumerate(self.train_set):\n",
    "            # Using our chosen device\n",
    "            targets = batch[\"targets\"][:, self.target].to(self.device).unsqueeze(dim=-1)\n",
    "\n",
    "            # Backpropagate using the selected loss\n",
    "            outputs = self.model(batch)\n",
    "            loss = self.loss(outputs, targets)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(f\"Current loss {loss} Current batch {batch_idx}/{len(self.train_set)} ({100*batch_idx/len(self.train_set):.2f}%)\")\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            if batch_idx == len(self.train_set) - 1:\n",
    "                self.learning_curve.append(loss.item())\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                self.learning_rates.append(current_lr)\n",
    "\n",
    "            # Cleanup at the end of the batch\n",
    "            del batch\n",
    "            del targets\n",
    "            del loss\n",
    "            del outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    def _eval_model(self):\n",
    "        val_loss = torch.zeros(1).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(self.valid_set):\n",
    "                pred_val = self.model(batch)\n",
    "                targets = batch[\"targets\"][:, self.target].to(self.device).unsqueeze(dim=-1)\n",
    "                \n",
    "                val_loss = val_loss + self.loss(pred_val, targets)\n",
    "                \n",
    "                del targets\n",
    "                del pred_val\n",
    "\n",
    "        return val_loss/(batch_idx+1)\n",
    "\n",
    "    def _train(self, num_epoch: int = 3, early_stopping: int = 30, alpha: float = 0.9):\n",
    "        \"\"\" Method to train the model\n",
    "        Args:\n",
    "            num_epoch: number of epochs you want to train for\n",
    "            alpha: exponential smoothing factor\n",
    "        \"\"\"\n",
    "        patience = 0\n",
    "        for epoch in range(num_epoch):\n",
    "            self._train_epoch()\n",
    "            # Validate at the end of an epoch\n",
    "            val_loss = self._eval_model()\n",
    "            print(f\"### End of the epoch : Validation loss for {epoch} is {val_loss.item()}\")\n",
    "            self.scheduler.step(val_loss)\n",
    "            val_loss_s = val_loss.item()\n",
    "            # Exponential smoothing for validation\n",
    "            self.valid_perf.append(val_loss_s if epoch == 0 else alpha*val_loss_s + (1-alpha)*self.valid_perf[-1])\n",
    "            \n",
    "            if epoch != 0 and min(min_loss, val_loss_s) == min_loss:\n",
    "                patience +=1\n",
    "                if patience >= early_stopping:\n",
    "                    break\n",
    "            else:\n",
    "                patience = 0\n",
    "\n",
    "            min_loss = val_loss_s if epoch == 0 else min(min_loss, val_loss_s)\n",
    "\n",
    "            del val_loss        \n",
    "\n",
    "    def plot_data(self):\n",
    "        p_data = (self.learning_curve, self.valid_perf, self.learning_rates)\n",
    "        plot_names = ['Learning curve','Validation loss for every 400 batches', 'Learning rates']\n",
    "\n",
    "        for i in range(3):\n",
    "            self.summaries_axes[i].plot(range(len(p_data[i])), p_data[i])\n",
    "            self.summaries_axes[i].set_ylabel('Loss')\n",
    "            self.summaries_axes[i].set_xlabel('Epochs')\n",
    "            self.summaries_axes[i].set_xlim((0, len(p_data[i])))\n",
    "            self.summaries_axes[i].set_title(plot_names[i])\n",
    "\n",
    "        plt.savefig('Loss_plot.png', dpi=800)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data_loader import PaiNNDataLoader\n",
    "from model import PaiNNModel\n",
    "from trainer import Trainer\n",
    "from utils import mse\n",
    "\n",
    "def training():\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"{device} will be used for training the PaiNN model\")\n",
    "        model = PaiNNModel(r_cut=5, \n",
    "                device=device\n",
    "                ).to(device)\n",
    "\n",
    "        train_set = PaiNNDataLoader(r_cut=5, \n",
    "                                    batch_size=100\n",
    "        )\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr = 5e-4, weight_decay = 0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience = 5)\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            loss=mse,\n",
    "            target=2,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_set,\n",
    "            scheduler=scheduler,\n",
    "            device=device\n",
    "        )\n",
    "        trainer._train(num_epoch = 3, early_stopping = 30)\n",
    "        trainer.plot_data()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
