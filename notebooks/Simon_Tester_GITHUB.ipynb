{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 15:42:05.578259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 15:42:06.341864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-27 15:42:06.341929: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-27 15:42:09.061543: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-27 15:42:09.061772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-27 15:42:09.061793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing record file, delete if you want to re-fetch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 15:42:16.920545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-11-27 15:42:16.920630: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-11-27 15:42:16.920671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Katrines): /proc/driver/nvidia/version does not exist\n",
      "2023-11-27 15:42:16.921280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Import functions and load data\n",
    "import os\n",
    "os.chdir(\"../src\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dataloader import qm9_parse, qm9_fetch\n",
    "import dmol\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "qm9_records = qm9_fetch()\n",
    "data = qm9_parse(qm9_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = data.shuffle(7000, reshuffle_each_iteration=False)\n",
    "test_set = shuffled_data.take(1000)\n",
    "valid_set = shuffled_data.skip(1000).take(1000)\n",
    "train_set = shuffled_data.skip(2000).take(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convert_record(d, atom_types=100, embedding_dim=128):\n",
    "    # break up record\n",
    "    (e, x), y = d\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    e = torch.tensor(e.numpy())\n",
    "    x = torch.tensor(x.numpy())\n",
    "    r = x[:, :3]\n",
    "\n",
    "    # Assuming atom indices start from 1\n",
    "    e = e - 1\n",
    "    e = torch.clamp(e, 0, atom_types - 1)  # Ensure indices are within valid range\n",
    "\n",
    "    # Embedding\n",
    "    embedding_layer = nn.Embedding(num_embeddings=atom_types, embedding_dim=embedding_dim)\n",
    "    s = embedding_layer(e)\n",
    "\n",
    "    return (s, r), y.numpy()[13]  # Select attribute at index 13\n",
    "\n",
    "\n",
    "#\n",
    "def x2e(x, cutoff_distance=5.0):\n",
    "    \"\"\"convert xyz coordinates to pairwise distance with a cutoff distance\"\"\"\n",
    "   # Calculate pairwise distances\n",
    "   # this calculates the norm\n",
    "    #r0 = (x- x[:, None, :]) #TODO: RIJ\n",
    "    r2 = torch.sqrt(((x - x[:, None, :])**2).sum(dim=-1))\n",
    "\n",
    "    # Create a mask for distances less than cutoff_distance\n",
    "    mask = (r2>0) & (r2 <= cutoff_distance)\n",
    "\n",
    "    # Use the mask to set values in the tensor\n",
    "    r_ij = torch.where(mask, r2, torch.zeros_like(r2))\n",
    "\n",
    "    # Generate edge index matrix\n",
    "    #edge_index = torch.nonzero(mask, as_tuple=False)\n",
    "\n",
    "    #edge_mask = (r2 > 0) & (r2 < cutoff_distance)\n",
    "    edge_indices = mask.nonzero(as_tuple=True)\n",
    "    edge_index = torch.stack(edge_indices)\n",
    "    #edge_index = edge_index.resize_(2,len(mask))\n",
    "\n",
    "    return r_ij, edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in test_set:\n",
    "#     (s, r_ij), y_raw = convert_record(d)\n",
    "\n",
    "\n",
    "# Assuming test_set is a list of data points\n",
    "s_j_samlet = []\n",
    "r_ij_samlet = []\n",
    "y_raw_samlet =[]\n",
    "\n",
    "for d in train_set:\n",
    "    (s_j, r_ij), y_raw = convert_record(d)\n",
    "    s_j_samlet.append(s_j)\n",
    "\n",
    "    r2, edge_index = x2e(r_ij)\n",
    "    r_ij_samlet.append(r2)\n",
    "    y_raw_samlet.append(y_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2813,  0.6982,  1.3782,  ...,  2.2824,  0.1095,  0.0165],\n",
       "        [-0.2957,  2.3361,  0.7956,  ..., -0.2223, -0.0924,  0.0515],\n",
       "        [ 0.2813,  0.6982,  1.3782,  ...,  2.2824,  0.1095,  0.0165],\n",
       "        ...,\n",
       "        [ 0.5694, -0.2632, -0.2392,  ...,  0.1870,  1.4736, -0.6734],\n",
       "        [ 0.5694, -0.2632, -0.2392,  ...,  0.1870,  1.4736, -0.6734],\n",
       "        [ 0.5694, -0.2632, -0.2392,  ...,  0.1870,  1.4736, -0.6734]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Kat tror at vi her skal zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize y values first and transform after prediction\n",
    "ys = [convert_record(d)[1] for d in train_set]\n",
    "train_ym = np.mean(ys)\n",
    "train_ys = np.std(ys)\n",
    "def transform_label(y):\n",
    "    return (y - train_ym) / train_ys\n",
    "def transform_prediction(y):\n",
    "    return y * train_ys + train_ym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class CosineCutoff(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cutoff=5.0):\n",
    "        super(CosineCutoff, self).__init__()\n",
    "        #self.register_buffer(\"cutoff\", torch.FloatTensor([cutoff]))\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def forward(self, distances):\n",
    "        \"\"\"Compute cutoff.\n",
    "\n",
    "        Args:\n",
    "            distances (torch.Tensor): values of interatomic distances.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: values of cutoff function.\n",
    "\n",
    "        \"\"\"\n",
    "        # Compute values of cutoff function\n",
    "        cutoffs = 0.5 * (torch.cos(distances * np.pi / self.cutoff) + 1.0)\n",
    "        # Remove contributions beyond the cutoff radius\n",
    "        cutoffs *= (distances < self.cutoff).float()\n",
    "        return cutoffs\n",
    "\n",
    "class BesselBasis(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Sine for radial basis expansion with coulomb decay. (0th order Bessel from DimeNet)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cutoff=5.0, n_rbf=20):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cutoff: radial cutoff\n",
    "            n_rbf: number of basis functions.\n",
    "        \"\"\"\n",
    "        super(BesselBasis, self).__init__()\n",
    "        # compute offset and width of Gaussian functions\n",
    "        freqs = torch.arange(1, n_rbf + 1) * math.pi / cutoff\n",
    "        self.register_buffer(\"freqs\", freqs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = torch.norm(inputs, p=2, dim=1)\n",
    "        a = self.freqs\n",
    "        ax = torch.outer(inputs,a)\n",
    "        sinax = torch.sin(ax)\n",
    "\n",
    "        norm = torch.where(inputs == 0, torch.tensor(1.0, device=inputs.device), inputs)\n",
    "        y = sinax / norm[:,None]\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/katrine_bay/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages (from torch-geometric) (1.26.1)\n",
      "Requirement already satisfied: scikit-learn in /home/katrine_bay/.local/lib/python3.10/site-packages (from torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/katrine_bay/.local/lib/python3.10/site-packages (from torch-geometric) (5.9.4)\n",
      "Requirement already satisfied: pyparsing in /home/katrine_bay/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scipy in /home/katrine_bay/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages (from torch-geometric) (1.11.3)\n",
      "Requirement already satisfied: requests in /home/katrine_bay/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/katrine_bay/.local/lib/python3.10/site-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in /home/katrine_bay/.local/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/katrine_bay/.local/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/katrine_bay/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages (from requests->torch-geometric) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/katrine_bay/.local/lib/python3.10/site-packages (from requests->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/katrine_bay/.local/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/katrine_bay/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/katrine_bay/.local/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/katrine_bay/.local/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing, radius_graph\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "import ase\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "from torch.nn import Embedding, Sequential, Linear, ModuleList, Module\n",
    "import numpy as np\n",
    "from torch import linalg as LA\n",
    "import math\n",
    "\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassPaiNN(MessagePassing):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20):\n",
    "        super(MessagePassPaiNN, self).__init__(aggr='add')\n",
    "\n",
    "        self.lin1 = Linear(num_feat, out_channels)\n",
    "        self.lin2 = Linear(out_channels, 3*out_channels)\n",
    "        self.lin_rbf = Linear(n_rbf, 3*out_channels)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        #self.prepare = Prepare_Message_Vector(num_nodes)\n",
    "        self.RBF = BesselBasis(cut_off, n_rbf)\n",
    "        self.f_cut = CosineCutoff(cut_off)\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "    def forward(self, s,v, edge_index, edge_attr):\n",
    "\n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "\n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "\n",
    "        x =torch.cat([s, v], dim = -1)\n",
    "\n",
    "\n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr\n",
    "                            ,flat_shape_s=flat_shape_s, flat_shape_v=flat_shape_v)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j, edge_attr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "\n",
    "        # Split Input into s_j and v_j\n",
    "        s_j, v_j = torch.split(x_j, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        # r_ij channel\n",
    "        rbf = self.RBF(edge_attr)\n",
    "        ch1 = self.lin_rbf(rbf)\n",
    "        cut = self.f_cut(edge_attr.norm(dim=-1))\n",
    "        W = torch.einsum('ij,i->ij',ch1, cut) # ch1 * f_cut\n",
    "\n",
    "        # s_j channel\n",
    "        phi = self.lin1(s_j)\n",
    "        phi = self.silu(phi)\n",
    "        phi = self.lin2(phi)\n",
    "\n",
    "        # Split\n",
    "        left, dsm, right = torch.tensor_split(phi*W,3,dim=-1)\n",
    "\n",
    "        # v_j channel\n",
    "        normalized = Func.normalize(edge_attr, p=2, dim=1)\n",
    "\n",
    "        v_j = v_j.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        hadamard_right = torch.einsum('ij,ik->ijk',right, normalized)\n",
    "        hadamard_left = torch.einsum('ijk,ij->ijk',v_j,left)\n",
    "        dvm = hadamard_left + hadamard_right\n",
    "\n",
    "        # Prepare vector for update\n",
    "        x_j = torch.cat((dsm,dvm.flatten(-2)), dim=-1)\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, out_aggr,flat_shape_s, flat_shape_v):\n",
    "\n",
    "        s_j, v_j = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        return s_j, v_j.reshape(-1, int(flat_shape_v/3), 3)\n",
    "class MessagePassPaiNN_NE(MessagePassing):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20):\n",
    "        super(MessagePassPaiNN_NE, self).__init__(aggr=\"add\")\n",
    "\n",
    "        self.lin1 = Linear(num_feat, out_channels)\n",
    "        self.lin2 = Linear(out_channels, 3 * out_channels)\n",
    "        self.lin_rbf = Linear(n_rbf, 3 * out_channels)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        # self.prepare = Prepare_Message_Vector(num_nodes)\n",
    "        self.RBF = BesselBasis(cut_off, n_rbf)\n",
    "        self.f_cut = CosineCutoff(cut_off)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_feat = num_feat\n",
    "\n",
    "    def forward(self, s, v, s_nuc, v_nuc, edge_index, edge_attr):\n",
    "\n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "\n",
    "        s_nuc = s_nuc.flatten(-1)\n",
    "        v_nuc = v_nuc.flatten(-2)\n",
    "\n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "\n",
    "        n_nuc = s_nuc.shape[0]\n",
    "        n_elec = s.shape[0]\n",
    "\n",
    "        x_p = torch.cat([s_nuc, v_nuc], dim=-1)  # nuclei\n",
    "        x = torch.cat([s, v], dim=-1)  # electrons\n",
    "\n",
    "        x = self.propagate(\n",
    "            edge_index,\n",
    "            x=(x_p, x),\n",
    "            edge_attr=edge_attr,\n",
    "            flat_shape_s=flat_shape_s,\n",
    "            flat_shape_v=flat_shape_v,\n",
    "            size=(n_nuc, n_elec),\n",
    "        )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j, edge_attr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        # Split Input into s_j and v_j\n",
    "        s_j, v_j = torch.split(x_j, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "        # _, v_i = torch.split(x_i, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        # r_ij channel\n",
    "        rbf = self.RBF(edge_attr)\n",
    "        ch1 = self.lin_rbf(rbf)\n",
    "        cut = self.f_cut(edge_attr.norm(dim=-1))\n",
    "        W = torch.einsum(\"ij,i->ij\", ch1, cut)  # ch1 * f_cut\n",
    "\n",
    "        # s_j channel\n",
    "        phi = self.lin1(s_j)\n",
    "        phi = self.silu(phi)\n",
    "        phi = self.lin2(phi)\n",
    "\n",
    "        # Split\n",
    "        left, dsm, right = torch.split(phi * W, self.num_feat, dim=-1)\n",
    "\n",
    "        # v_j channel\n",
    "        normalized = Func.normalize(edge_attr, p=2, dim=1)\n",
    "\n",
    "        v_j = v_j.reshape(-1, int(flat_shape_v / 3), 3)\n",
    "        # v_i = v_i.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        # print(v_j - v_i)\n",
    "        hadamard_right = torch.einsum(\"ij,ik->ijk\", right, normalized)\n",
    "        hadamard_left = torch.einsum(\"ijk,ij->ijk\", v_j, left)\n",
    "        dvm = hadamard_left + hadamard_right\n",
    "\n",
    "        # Prepare vector for update\n",
    "        x_j = torch.cat((dsm, dvm.flatten(-2)), dim=-1)\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, out_aggr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        s_j, v_j = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        return s_j, v_j.reshape(-1, int(flat_shape_v / 3), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatePaiNN(torch.nn.Module):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes):\n",
    "        super(UpdatePaiNN, self).__init__()\n",
    "\n",
    "        self.lin_up = Linear(2*num_feat, out_channels)\n",
    "        self.denseU = Linear(num_feat,out_channels, bias = False)\n",
    "        self.denseV = Linear(num_feat,out_channels, bias = False)\n",
    "        self.lin2 = Linear(out_channels, 3*out_channels)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "\n",
    "    def forward(self, s,v):\n",
    "\n",
    "        # split and take linear combinations\n",
    "        #s, v = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "\n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "\n",
    "        v_u = v.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        v_ut = torch.transpose(v_u,1,2)\n",
    "        U = torch.transpose(self.denseU(v_ut),1,2)\n",
    "        V = torch.transpose(self.denseV(v_ut),1,2)\n",
    "\n",
    "\n",
    "        # form the dot product\n",
    "        UV =  torch.einsum('ijk,ijk->ij',U,V)\n",
    "\n",
    "        # s_j channel\n",
    "        nV = torch.norm(V, dim=-1)\n",
    "\n",
    "        s_u = torch.cat([s, nV], dim=-1)\n",
    "        s_u = self.lin_up(s_u)\n",
    "        s_u = Func.silu(s_u)\n",
    "        s_u = self.lin2(s_u)\n",
    "        #s_u = Func.silu(s_u)\n",
    "\n",
    "        # final split\n",
    "        top, middle, bottom = torch.tensor_split(s_u,3,dim=-1)\n",
    "\n",
    "        # outputs\n",
    "        dvu = torch.einsum('ijk,ij->ijk',v_u,top)\n",
    "        dsu = middle*UV + bottom\n",
    "\n",
    "        #update = torch.cat((dsu,dvu.flatten(-2)), dim=-1)\n",
    "\n",
    "        return dsu, dvu.reshape(-1, int(flat_shape_v/3), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaiNN(torch.nn.Module):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20, num_interactions=3):\n",
    "        super(PaiNN, self).__init__()\n",
    "        '''PyG implementation of PaiNN network of Schütt et. al. Supports two arrays\n",
    "           stored at the nodes of shape (num_nodes,num_feat,1) and (num_nodes, num_feat,3). For this\n",
    "           representation to be compatible with PyG, the arrays are flattened and concatenated.\n",
    "           Important to note is that the out_channels must match number of features'''\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cut_off = cut_off\n",
    "        self.n_rbf = n_rbf\n",
    "        self.linear = Linear(num_feat,num_feat)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        self.list_message = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN(num_feat, out_channels, num_nodes, cut_off, n_rbf)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.list_update = nn.ModuleList(\n",
    "            [\n",
    "                UpdatePaiNN(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, s,v, edge_index, edge_attr):\n",
    "\n",
    "\n",
    "        for i in range(self.num_interactions):\n",
    "\n",
    "            s_temp,v_temp = self.list_message[i](s,v, edge_index, edge_attr)\n",
    "            s, v = s_temp+s, v_temp+v\n",
    "            s_temp,v_temp = self.list_update[i](s,v)\n",
    "            s, v = s_temp+s, v_temp+v\n",
    "\n",
    "        s = self.linear(s)\n",
    "        s = self.silu(s)\n",
    "        s = self.linear(s)\n",
    "\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "from torch.nn import Linear\n",
    "\n",
    "# from message import MessagePassPaiNN, MessagePassPaiNN_NE\n",
    "# from update import UpdatePaiNN\n",
    "\n",
    "\n",
    "class PaiNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feat,\n",
    "        out_channels,\n",
    "        num_nodes,\n",
    "        cut_off=5.0,\n",
    "        n_rbf=20,\n",
    "        num_interactions=3,\n",
    "    ):\n",
    "        super(PaiNN, self).__init__()\n",
    "        \"\"\"PyG implementation of PaiNN network of Schütt et. al. Supports two arrays\n",
    "           stored at the nodes of shape (num_nodes,num_feat,1) and (num_nodes, num_feat,3). For this\n",
    "           representation to be compatible with PyG, the arrays are flattened and concatenated.\n",
    "           Important to note is that the out_channels must match number of features\"\"\"\n",
    "\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cut_off = cut_off\n",
    "        self.n_rbf = n_rbf\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_feat = num_feat\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(num_feat, num_feat)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        self.list_message = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN(num_feat, out_channels, num_nodes, cut_off, n_rbf)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.list_update = nn.ModuleList(\n",
    "            [\n",
    "                UpdatePaiNN(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, s, v, edge_index, edge_attr):\n",
    "\n",
    "        for i in range(self.num_interactions):\n",
    "\n",
    "            s_temp, v_temp = self.list_message[i](s, v, edge_index, edge_attr)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "            s_temp, v_temp = self.list_update[i](s, v)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "\n",
    "        s = self.lin(s)\n",
    "        s = self.silu(s)\n",
    "        s = self.lin(s)\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "class PaiNNElecNuc(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feat,\n",
    "        out_channels,\n",
    "        num_nodes,\n",
    "        cut_off=5.0,\n",
    "        n_rbf=20,\n",
    "        num_interactions=3,\n",
    "    ):\n",
    "        super(PaiNNElecNuc, self).__init__()\n",
    "        \"\"\"PyG implementation of PaiNN network of Schütt et. al. Supports two arrays\n",
    "           stored at the nodes of shape (num_nodes,num_feat,1) and (num_nodes, num_feat,3). For this\n",
    "           representation to be compatible with PyG, the arrays are flattened and concatenated.\n",
    "           Important to note is that the out_channels must match number of features\"\"\"\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cut_off = cut_off\n",
    "        self.n_rbf = n_rbf\n",
    "        self.linear = Linear(num_feat, num_feat)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        self.list_message = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN(num_feat, out_channels, num_nodes, cut_off, n_rbf)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.list_update = nn.ModuleList(\n",
    "            [\n",
    "                UpdatePaiNN(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.list_message_NE = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN_NE(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, s, v, s_nuc, v_nuc, edge_index, edge_attr, edge_index_nuc, edge_attr_nuc\n",
    "    ):\n",
    "\n",
    "        for i in range(self.num_interactions):\n",
    "\n",
    "            s_temp, v_temp = self.list_message[i](s, v, edge_index, edge_attr)\n",
    "            s_temp_NE, v_temp_NE = self.list_message_NE[i](\n",
    "                s, v, s_nuc, v_nuc, edge_index_nuc, edge_attr_nuc\n",
    "            )\n",
    "\n",
    "            s, v = s_temp + s + s_temp_NE, v_temp + v + v_temp_NE\n",
    "            s_temp, v_temp = self.list_update[i](s, v)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "\n",
    "        s = self.linear(s)\n",
    "        s = self.silu(s)\n",
    "        s = self.linear(s)\n",
    "\n",
    "        return s, v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersøg Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\Simon_Tester_GITHUB.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(num_nodes, F)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Call the forward method of your model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m PA\u001b[39m.\u001b[39;49mforward(s, v, edge_index, edge_attr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Access the predicted values from the output\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m predicted_values \u001b[39m=\u001b[39m output\n",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\Simon_Tester_GITHUB.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, s, v, edge_index, edge_attr):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_interactions):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         s_temp, v_temp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlist_message[i](s, v, edge_index, edge_attr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         s, v \u001b[39m=\u001b[39m s_temp \u001b[39m+\u001b[39m s, v_temp \u001b[39m+\u001b[39m v\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         s_temp, v_temp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_update[i](s, v)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\Simon_Tester_GITHUB.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m flat_shape_v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m flat_shape_s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mcat([s, v], dim \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, edge_attr\u001b[39m=\u001b[39medge_attr\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                     ,flat_shape_s\u001b[39m=\u001b[39mflat_shape_s, flat_shape_v\u001b[39m=\u001b[39mflat_shape_v)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GITHUB.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
