{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../src\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dataloader import qm9_parse, qm9_fetch\n",
    "import dmol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing record file, delete if you want to re-fetch\n"
     ]
    }
   ],
   "source": [
    "qm9_records = qm9_fetch()\n",
    "\n",
    "data = qm9_parse(qm9_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in data:\n",
    "#     print(d)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with 5000 and use 1000 for test\n",
    "shuffled_data = data.shuffle(700, reshuffle_each_iteration=False)\n",
    "test_set = shuffled_data.take(100)\n",
    "valid_set = shuffled_data.skip(100).take(100)\n",
    "train_set = shuffled_data.skip(200).take(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the embedding layer outside the loop\n",
    "embedding_layer = nn.Embedding(16, 128)\n",
    "\n",
    "def convert_record(d):\n",
    "    # break up record\n",
    "    (e, x), y = d\n",
    "    e = e.numpy()\n",
    "    x= x.numpy()\n",
    "    r= x[:,:3]\n",
    "    # embedding= nn.Embedding(100,128,padding_idx=0)\n",
    "    e=torch.tensor(e)\n",
    "    e = embedding(e)\n",
    "    r =torch.tensor(r)\n",
    "    return(e,r),y.numpy()[13]\n",
    "\n",
    "# for d in data:\n",
    "#     print(d)\n",
    "#     (e, x), y = convert_record(d)\n",
    "#     print(\"Embedded Atomic Numbers:\\n\", e)\n",
    "#     print(\"Coordinates:\\n\", x)\n",
    "#     print(\"Label:\", y)\n",
    "#     print()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_record(d):\n",
    "    # break up record\n",
    "    (e, x), y = d\n",
    "    e = e.numpy()\n",
    "    x= x.numpy()\n",
    "    r= x[:,:3]\n",
    "    embedding= nn.Embedding(100,128,padding_idx=0)\n",
    "    e=torch.tensor(e)\n",
    "    s_j = embedding(e)\n",
    "    r =torch.tensor(r)\n",
    "    return(s_j,r),y.numpy()[13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2e(x):\n",
    "    \"\"\"convert xyz coordinates to inverse pairwise distance\"\"\"\n",
    "    r2 = torch.sum((x - x[:, None, :]) ** 2, axis=-1)\n",
    "    # r2 = jnp.sum((x - x[:, jnp.newaxis, :]) ** 2, axis=-1)\n",
    "    # e = jnp.where(r2 != 0, 1 / r2, 0.0)\n",
    "    e = torch.sqrt(torch.where(r2 != 0, r2, 0.0))\n",
    "\n",
    "    return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in data:\n",
    "    (s_j,r),response_var = convert_record(d)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0127,  1.0858,  0.0080])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(r[0])\n",
    "print(len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0127,  1.0858,  0.0080])\n",
      "tensor([ 0.0022, -0.0060,  0.0020])\n",
      "tensor([1.0117e+00, 1.4638e+00, 2.7657e-04])\n",
      "tensor([-0.5408,  1.4475, -0.8766])\n",
      "tensor([-0.5238,  1.4379,  0.9064])\n"
     ]
    }
   ],
   "source": [
    "for atom in r:\n",
    "    print(atom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_r_ij(r, r_cut=5.0):\n",
    "    r_ij = torch.tensor([])\n",
    "    for i in range(len(r)):\n",
    "        for j in range(len(r)):\n",
    "            if torch.norm(r[i] - r[j]) <r_cut:\n",
    "                r_ij = torch.cat((r_ij, r[i] - r[j])) #important\n",
    "            else:\n",
    "                continue\n",
    "        return r_ij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vi bruger denne\n",
    "def create_r_ij(r, r_cut=5.0):\n",
    "    r_ij = []\n",
    "    for i in range(len(r)):\n",
    "        for j in range(len(r)):\n",
    "            if torch.norm(r[i] - r[j]) <r_cut:\n",
    "                r_ij.append(r[i] - r[j]) #important\n",
    "            else:\n",
    "                continue\n",
    "        return r_ij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., 0., 0.]),\n",
       " tensor([-0.0148,  1.0918,  0.0060]),\n",
       " tensor([-1.0244, -0.3779,  0.0077]),\n",
       " tensor([ 0.5281, -0.3617,  0.8846]),\n",
       " tensor([ 0.5111, -0.3521, -0.8984])]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_r_ij(r,r_cut=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input\n",
    "\n",
    "r_ij = create_r_ij(r,r_cut=5.0) #vectorization\n",
    "A = x2e(r) # adjacency matrix\n",
    "r_pos = r # position matrix\n",
    "s_j = s_j\n",
    "r_cut = 5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [-0.0148,  1.0918,  0.0060],\n",
       "        [-1.0244, -0.3779,  0.0077],\n",
       "        [ 0.5281, -0.3617,  0.8846],\n",
       "        [ 0.5111, -0.3521, -0.8984]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r_ij_tensor = torch.stack(r_ij)\n",
    "r_ij_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [-0.0068,  0.4999,  0.0028],\n",
       "        [-0.4691, -0.1731,  0.0035],\n",
       "        [ 0.2418, -0.1656,  0.4051],\n",
       "        [ 0.2340, -0.1612, -0.4114]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_norm = r_ij_tensor/(torch.norm(r_ij_tensor))\n",
    "v_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Message block\n",
    "\n",
    "v_norm = r_ij_tensor/(torch.norm(r_ij_tensor))\n",
    "\n",
    "v_j = torch.zeros(128)\n",
    "\n",
    "class phi(nn.Module):\n",
    "\n",
    "     def __init__(self):\n",
    "        super().__init__()\n",
    "        activation_fn = nn.SiLU\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_j, 128),\n",
    "            activation_fn(),\n",
    "            nn.Linear(128, 384),\n",
    "        )\n",
    "class w(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        RBF = []\n",
    "        for n in range(21):\n",
    "            if i>0:\n",
    "                RBF.append = torch.sin((n*torch.pi()/r_cut)*r_ij)/r_ij\n",
    "            else:\n",
    "                continue\n",
    "        f_c=0.5*torch.cos(torch.pi()*r_ij/r_cut)+1\n",
    "        fcRBF = RBF * f_c\n",
    "        self.fcRBF=nn.linear(fcRBF,384)\n",
    "\n",
    "\n",
    "def forward(self, input1, input2):\n",
    "    phi = self.net(input1)\n",
    "    w = self.net(input2)\n",
    "    output = phi * w\n",
    "    output = torch.split(output,3)\n",
    "    output1 = output[0] * v_j\n",
    "    s_m = torch.sum(output[1]) + s_j\n",
    "    output3 = output[2]*v_norm\n",
    "    v_m= torch.sum(output1+output3) + v_j\n",
    "    return v_m, s_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/hansmoeller/Documents/GitHub/02456_DL_Project/notebooks/Network.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hansmoeller/Documents/GitHub/02456_DL_Project/notebooks/Network.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m v_m, s_m \u001b[39m=\u001b[39m forward(\u001b[39mself\u001b[39m, s_j, r_ij)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "v_m, s_m = forward(self, s_j, r_ij) # input1, input2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Update block\n",
    "\n",
    "class u(nn.Module):\n",
    "      def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(v_m,128)\n",
    "class v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(v_m,128)\n",
    "class s(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        activation_fn = nn.SiLU\n",
    "        self.net = nn.Sequential(\n",
    "            torch.stack(v_norm,s_m),\n",
    "            nn.Linear(256,128),\n",
    "            activation_fn(),\n",
    "            nn.Linear(128,384))\n",
    "\n",
    "def forward(self,input3,input4,input5):\n",
    "    U = self.net(input3)\n",
    "    V = self.net(input4)\n",
    "    S = self.net(input5)\n",
    "    V_dup = V.repeat(128,2)\n",
    "    S = torch.split(S,3)\n",
    "    output4 = S[0]*U\n",
    "    output5 = S[1]*V_dup\n",
    "    output6 = S[2]+output5\n",
    "    v_u = output4 + v_m\n",
    "    s_u = output6 + s_m\n",
    "    return v_u, s_u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Class pain\n",
    "\n",
    "#Kør 3x message og 3x update (skiftesvis)\n",
    "\n",
    "#Linear, SiLU, Linear, output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class PAINN(nn.Module):\n",
    "#     def __init__(self, n_basis=int(128)):\n",
    "#         super(PAINN, self).__init__()\n",
    "#         self.n_basis = n_basis\n",
    "#         self.embedding = nn.Embedding(16,n_basis,padding_idx=0)\n",
    "\n",
    "#     def x2e(r):\n",
    "#     \"\"\"convert xyz coordinates to pairwise distance\"\"\"\n",
    "#     r2 = np.sqrt(np.sum((r - r[:, np.newaxis, :]) ** 2, axis=-1))\n",
    "#     r_cut = 5\n",
    "#     r_ij = np.where(r2 < r_cut)\n",
    "#     return r_ij\n",
    "\n",
    "\n",
    "\n",
    "#     def init_weights(g, n, m):\n",
    "#     we = np.random.normal(size=(n, m), scale=1e-1)\n",
    "#     wb = np.random.normal(size=(m), scale=1e-1)\n",
    "#     wv = np.random.normal(size=(m, n), scale=1e-1)\n",
    "#     wu = np.random.normal(size=(n, g), scale=1e-1)\n",
    "#     return [we, wb, wv, wu]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class update(nn.Module):\n",
    "\n",
    "class message(nn.Module):\n",
    "\n",
    "     def __init__(self):\n",
    "        super().__init__()\n",
    "        activation_fn = nn.SiLU\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_j, 128),\n",
    "            activation_fn(),\n",
    "            nn.Linear(128, 128),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class PAINN(nn.Module):\n",
    "    def __init__(self, n_basis=int(128)):\n",
    "        super(PAINN, self).__init__()\n",
    "        self.n_basis = n_basis\n",
    "        self.embedding = nn.Embedding(16,n_basis,padding_idx=0)\n",
    "\n",
    "    def x2e(r):\n",
    "    \"\"\"convert xyz coordinates to pairwise distance\"\"\"\n",
    "    r2 = np.sqrt(np.sum((r - r[:, np.newaxis, :]) ** 2, axis=-1))\n",
    "    r_cut = 5\n",
    "    r_ij = np.where(r2 < r_cut)\n",
    "    return r_ij\n",
    "\n",
    "    def init_weights(g, n, m):\n",
    "    we = np.random.normal(size=(n, m), scale=1e-1)\n",
    "    wb = np.random.normal(size=(m), scale=1e-1)\n",
    "    wv = np.random.normal(size=(m, n), scale=1e-1)\n",
    "    wu = np.random.normal(size=(n, g), scale=1e-1)\n",
    "    return [we, wb, wv, wu]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'schnetpack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\src\\Network.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mschnetpack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperties\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mproperties\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mschnetpack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msnn\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mPaiNN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPaiNNInteraction\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPaiNNMixing\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'schnetpack'"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Dict, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import schnetpack.properties as properties\n",
    "import schnetpack.nn as snn\n",
    "\n",
    "__all__ = [\"PaiNN\", \"PaiNNInteraction\", \"PaiNNMixing\"]\n",
    "\n",
    "\n",
    "class PaiNNInteraction(nn.Module):\n",
    "    r\"\"\"PaiNN interaction block for modeling equivariant interactions of atomistic systems.\"\"\"\n",
    "\n",
    "    def __init__(self, n_atom_basis: int, activation: Callable):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_atom_basis: number of features to describe atomic environments.\n",
    "            activation: if None, no activation function is used.\n",
    "            epsilon: stability constant added in norm to prevent numerical instabilities\n",
    "        \"\"\"\n",
    "        super(PaiNNInteraction, self).__init__()\n",
    "        self.n_atom_basis = n_atom_basis\n",
    "\n",
    "        self.interatomic_context_net = nn.Sequential(\n",
    "            snn.Dense(n_atom_basis, n_atom_basis, activation=activation),\n",
    "            snn.Dense(n_atom_basis, 3 * n_atom_basis, activation=None),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        q: torch.Tensor,\n",
    "        mu: torch.Tensor,\n",
    "        Wij: torch.Tensor,\n",
    "        dir_ij: torch.Tensor,\n",
    "        idx_i: torch.Tensor,\n",
    "        idx_j: torch.Tensor,\n",
    "        n_atoms: int,\n",
    "    ):\n",
    "        \"\"\"Compute interaction output.\n",
    "\n",
    "        Args:\n",
    "            q: scalar input values\n",
    "            mu: vector input values\n",
    "            Wij: filter\n",
    "            idx_i: index of center atom i\n",
    "            idx_j: index of neighbors j\n",
    "\n",
    "        Returns:\n",
    "            atom features after interaction\n",
    "        \"\"\"\n",
    "        # inter-atomic\n",
    "        x = self.interatomic_context_net(q)\n",
    "        xj = x[idx_j]\n",
    "        muj = mu[idx_j]\n",
    "        x = Wij * xj\n",
    "\n",
    "        dq, dmuR, dmumu = torch.split(x, self.n_atom_basis, dim=-1)\n",
    "        dq = snn.scatter_add(dq, idx_i, dim_size=n_atoms)\n",
    "        dmu = dmuR * dir_ij[..., None] + dmumu * muj\n",
    "        dmu = snn.scatter_add(dmu, idx_i, dim_size=n_atoms)\n",
    "\n",
    "        q = q + dq\n",
    "        mu = mu + dmu\n",
    "\n",
    "        return q, mu\n",
    "\n",
    "\n",
    "class PaiNNMixing(nn.Module):\n",
    "    r\"\"\"PaiNN interaction block for mixing on atom features.\"\"\"\n",
    "\n",
    "    def __init__(self, n_atom_basis: int, activation: Callable, epsilon: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_atom_basis: number of features to describe atomic environments.\n",
    "            activation: if None, no activation function is used.\n",
    "            epsilon: stability constant added in norm to prevent numerical instabilities\n",
    "        \"\"\"\n",
    "        super(PaiNNMixing, self).__init__()\n",
    "        self.n_atom_basis = n_atom_basis\n",
    "\n",
    "        self.intraatomic_context_net = nn.Sequential(\n",
    "            snn.Dense(2 * n_atom_basis, n_atom_basis, activation=activation),\n",
    "            snn.Dense(n_atom_basis, 3 * n_atom_basis, activation=None),\n",
    "        )\n",
    "        self.mu_channel_mix = snn.Dense(\n",
    "            n_atom_basis, 2 * n_atom_basis, activation=None, bias=False\n",
    "        )\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, q: torch.Tensor, mu: torch.Tensor):\n",
    "        \"\"\"Compute intraatomic mixing.\n",
    "\n",
    "        Args:\n",
    "            q: scalar input values\n",
    "            mu: vector input values\n",
    "\n",
    "        Returns:\n",
    "            atom features after interaction\n",
    "        \"\"\"\n",
    "        ## intra-atomic\n",
    "        mu_mix = self.mu_channel_mix(mu)\n",
    "        mu_V, mu_W = torch.split(mu_mix, self.n_atom_basis, dim=-1)\n",
    "        mu_Vn = torch.sqrt(torch.sum(mu_V**2, dim=-2, keepdim=True) + self.epsilon)\n",
    "\n",
    "        ctx = torch.cat([q, mu_Vn], dim=-1)\n",
    "        x = self.intraatomic_context_net(ctx)\n",
    "\n",
    "        dq_intra, dmu_intra, dqmu_intra = torch.split(x, self.n_atom_basis, dim=-1)\n",
    "        dmu_intra = dmu_intra * mu_W\n",
    "\n",
    "        dqmu_intra = dqmu_intra * torch.sum(mu_V * mu_W, dim=1, keepdim=True)\n",
    "\n",
    "        q = q + dq_intra + dqmu_intra\n",
    "        mu = mu + dmu_intra\n",
    "        return q, mu\n",
    "\n",
    "\n",
    "class PaiNN(nn.Module):\n",
    "    \"\"\"PaiNN - polarizable interaction neural network\n",
    "\n",
    "    References:\n",
    "\n",
    "    .. [#painn1] Schütt, Unke, Gastegger:\n",
    "       Equivariant message passing for the prediction of tensorial properties and molecular spectra.\n",
    "       ICML 2021, http://proceedings.mlr.press/v139/schutt21a.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_atom_basis: int,\n",
    "        n_interactions: int,\n",
    "        radial_basis: nn.Module,\n",
    "        cutoff_fn: Optional[Callable] = None,\n",
    "        activation: Optional[Callable] = F.silu,\n",
    "        max_z: int = 100,\n",
    "        shared_interactions: bool = False,\n",
    "        shared_filters: bool = False,\n",
    "        epsilon: float = 1e-8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_atom_basis: number of features to describe atomic environments.\n",
    "                This determines the size of each embedding vector; i.e. embeddings_dim.\n",
    "            n_interactions: number of interaction blocks.\n",
    "            radial_basis: layer for expanding interatomic distances in a basis set\n",
    "            cutoff_fn: cutoff function\n",
    "            activation: activation function\n",
    "            shared_interactions: if True, share the weights across\n",
    "                interaction blocks.\n",
    "            shared_interactions: if True, share the weights across\n",
    "                filter-generating networks.\n",
    "            epsilon: stability constant added in norm to prevent numerical instabilities\n",
    "        \"\"\"\n",
    "        super(PaiNN, self).__init__()\n",
    "\n",
    "        self.n_atom_basis = n_atom_basis\n",
    "        self.n_interactions = n_interactions\n",
    "        self.cutoff_fn = cutoff_fn\n",
    "        self.cutoff = cutoff_fn.cutoff\n",
    "        self.radial_basis = radial_basis\n",
    "\n",
    "        self.embedding = nn.Embedding(max_z, n_atom_basis, padding_idx=0)\n",
    "\n",
    "        self.share_filters = shared_filters\n",
    "\n",
    "        if shared_filters:\n",
    "            self.filter_net = snn.Dense(\n",
    "                self.radial_basis.n_rbf, 3 * n_atom_basis, activation=None\n",
    "            )\n",
    "        else:\n",
    "            self.filter_net = snn.Dense(\n",
    "                self.radial_basis.n_rbf,\n",
    "                self.n_interactions * n_atom_basis * 3,\n",
    "                activation=None,\n",
    "            )\n",
    "\n",
    "        self.interactions = snn.replicate_module(\n",
    "            lambda: PaiNNInteraction(\n",
    "                n_atom_basis=self.n_atom_basis, activation=activation\n",
    "            ),\n",
    "            self.n_interactions,\n",
    "            shared_interactions,\n",
    "        )\n",
    "        self.mixing = snn.replicate_module(\n",
    "            lambda: PaiNNMixing(\n",
    "                n_atom_basis=self.n_atom_basis, activation=activation, epsilon=epsilon\n",
    "            ),\n",
    "            self.n_interactions,\n",
    "            shared_interactions,\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs: Dict[str, torch.Tensor]):\n",
    "        \"\"\"\n",
    "        Compute atomic representations/embeddings.\n",
    "\n",
    "        Args:\n",
    "            inputs (dict of torch.Tensor): SchNetPack dictionary of input tensors.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: atom-wise representation.\n",
    "            list of torch.Tensor: intermediate atom-wise representations, if\n",
    "            return_intermediate=True was used.\n",
    "        \"\"\"\n",
    "        # get tensors from input dictionary\n",
    "        atomic_numbers = inputs[properties.Z]\n",
    "        r_ij = inputs[properties.Rij]\n",
    "        idx_i = inputs[properties.idx_i]\n",
    "        idx_j = inputs[properties.idx_j]\n",
    "        n_atoms = atomic_numbers.shape[0]\n",
    "\n",
    "        # compute atom and pair features\n",
    "        d_ij = torch.norm(r_ij, dim=1, keepdim=True)\n",
    "        dir_ij = r_ij / d_ij\n",
    "        phi_ij = self.radial_basis(d_ij)\n",
    "        fcut = self.cutoff_fn(d_ij)\n",
    "\n",
    "        filters = self.filter_net(phi_ij) * fcut[..., None]\n",
    "        if self.share_filters:\n",
    "            filter_list = [filters] * self.n_interactions\n",
    "        else:\n",
    "            filter_list = torch.split(filters, 3 * self.n_atom_basis, dim=-1)\n",
    "\n",
    "        q = self.embedding(atomic_numbers)[:, None]\n",
    "        qs = q.shape\n",
    "        mu = torch.zeros((qs[0], 3, qs[2]), device=q.device)\n",
    "\n",
    "        for i, (interaction, mixing) in enumerate(zip(self.interactions, self.mixing)):\n",
    "            q, mu = interaction(q, mu, filter_list[i], dir_ij, idx_i, idx_j, n_atoms)\n",
    "            q, mu = mixing(q, mu)\n",
    "\n",
    "        q = q.squeeze(1)\n",
    "\n",
    "        inputs[\"scalar_representation\"] = q\n",
    "        inputs[\"vector_representation\"] = mu\n",
    "        return inputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
