{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 15:19:26.039962: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 15:19:26.273180: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-27 15:19:26.273201: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-27 15:19:27.853178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-27 15:19:27.855468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-27 15:19:27.855494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#Import functions and load data\n",
    "import os\n",
    "os.chdir(\"../src\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataloader import qm9_parse, qm9_fetch\n",
    "from dataloader import convert_record, x2e\n",
    "import dmol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing record file, delete if you want to re-fetch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 15:19:34.665544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-11-27 15:19:34.665646: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-11-27 15:19:34.665695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Katrines): /proc/driver/nvidia/version does not exist\n",
      "2023-11-27 15:19:34.666311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "qm9_records = qm9_fetch()\n",
    "data = qm9_parse(qm9_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take samples for test, validation and training\n",
    "shuffled_data = data.shuffle(7000, reshuffle_each_iteration=False)\n",
    "test_set = shuffled_data.take(1000)\n",
    "valid_set = shuffled_data.skip(1000).take(1000)\n",
    "train_set = shuffled_data.skip(2000).take(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_j_samlet = []\n",
    "r_ij_samlet = []\n",
    "y_raw_samlet =[]\n",
    "\n",
    "for d in train_set:\n",
    "    (s_j, r_ij), y_raw = convert_record(d)\n",
    "    s_j_samlet.append(s_j)\n",
    "\n",
    "    r2, edge_index = x2e(r_ij)\n",
    "    r_ij_samlet.append(r2)\n",
    "    y_raw_samlet.append(y_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester noget nyt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import GRU, Linear, ReLU, Sequential\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "from torch_geometric.utils import remove_self_loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 0\n",
    "dim = 64\n",
    "\n",
    "\n",
    "class MyTransform:\n",
    "    def __call__(self, data):\n",
    "        data = copy.copy(data)\n",
    "        data.y = data.y[:, target]  # Specify target.\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Complete:\n",
    "    def __call__(self, data):\n",
    "        data = copy.copy(data)\n",
    "        device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/molnet_publish/qm9.zip\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/src/data/qm9.tar.bz2/raw/qm9.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/notebooks/Katrine_data_1.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/notebooks/Katrine_data_1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/src/data/qm9.tar.bz2\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/notebooks/Katrine_data_1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m transform \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mCompose([MyTransform(), Complete(), T\u001b[39m.\u001b[39mDistance(norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/notebooks/Katrine_data_1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m dataset \u001b[39m=\u001b[39m QM9(path, transform\u001b[39m=\u001b[39;49mtransform)\u001b[39m.\u001b[39mshuffle()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/notebooks/Katrine_data_1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Normalize targets to mean = 0 and std = 1.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/notebooks/Katrine_data_1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m mean \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages/torch_geometric/datasets/qm9.py:145\u001b[0m, in \u001b[0;36mQM9.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root: \u001b[39mstr\u001b[39m, transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    143\u001b[0m              pre_transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    144\u001b[0m              pre_filter: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 145\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter)\n\u001b[1;32m    146\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:76\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     70\u001b[0m     root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m ):\n\u001b[0;32m---> 76\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter, log)\n\u001b[1;32m     77\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages/torch_geometric/data/dataset.py:99\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices: Optional[Sequence] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_download:\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download()\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_process:\n\u001b[1;32m    102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process()\n",
      "File \u001b[0;32m~/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages/torch_geometric/data/dataset.py:204\u001b[0m, in \u001b[0;36mDataset._download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    203\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_dir)\n\u001b[0;32m--> 204\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n",
      "File \u001b[0;32m~/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages/torch_geometric/datasets/qm9.py:178\u001b[0m, in \u001b[0;36mQM9.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mrdkit\u001b[39;00m  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     file_path \u001b[39m=\u001b[39m download_url(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_url, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_dir)\n\u001b[1;32m    179\u001b[0m     extract_zip(file_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_dir)\n\u001b[1;32m    180\u001b[0m     os\u001b[39m.\u001b[39munlink(file_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/Katrine_MLOps_env/lib/python3.10/site-packages/torch_geometric/data/download.py:40\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, folder, log, filename)\u001b[0m\n\u001b[1;32m     37\u001b[0m context \u001b[39m=\u001b[39m ssl\u001b[39m.\u001b[39m_create_unverified_context()\n\u001b[1;32m     38\u001b[0m data \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(url, context\u001b[39m=\u001b[39mcontext)\n\u001b[0;32m---> 40\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     41\u001b[0m     \u001b[39m# workaround for https://bugs.python.org/issue42853\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         chunk \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mread(\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m)\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/src/data/qm9.tar.bz2/raw/qm9.zip'"
     ]
    }
   ],
   "source": [
    "\n",
    "# path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'QM9')\n",
    "path = '/mnt/c/Dokumenter/Dokumenter/Git_Projects/02456_DL_Project/src/data/qm9.tar.bz2'\n",
    "\n",
    "transform = T.Compose([MyTransform(), Complete(), T.Distance(norm=False)])\n",
    "dataset = QM9(path, transform=transform).shuffle()\n",
    "\n",
    "# Normalize targets to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "mean, std = mean[:, target].item(), std[:, target].item()\n",
    "\n",
    "# Split datasets.\n",
    "test_dataset = dataset[:10000]\n",
    "val_dataset = dataset[10000:20000]\n",
    "train_dataset = dataset[20000:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Katrine_MLOps_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
