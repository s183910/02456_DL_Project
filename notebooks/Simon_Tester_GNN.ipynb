{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing record file, delete if you want to re-fetch\n"
     ]
    }
   ],
   "source": [
    "#Import functions and load data\n",
    "import os\n",
    "os.chdir(\"../src\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dataloader import qm9_parse, qm9_fetch\n",
    "import dmol\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "qm9_records = qm9_fetch()\n",
    "data = qm9_parse(qm9_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take samples for test, validation and training\n",
    "shuffled_data = data.shuffle(7000, reshuffle_each_iteration=False)\n",
    "test_set = shuffled_data.take(1000)\n",
    "valid_set = shuffled_data.skip(1000).take(1000)\n",
    "train_set = shuffled_data.skip(2000).take(5000)\n",
    "\n",
    "# for d in test_set:\n",
    "#     print(d)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convert_record(d, atom_types=100, embedding_dim=128):\n",
    "    # break up record\n",
    "    (e, x), y = d\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    e = torch.tensor(e.numpy())\n",
    "    x = torch.tensor(x.numpy())\n",
    "    r = x[:, :3]\n",
    "\n",
    "    # Assuming atom indices start from 1\n",
    "    e = e - 1\n",
    "    e = torch.clamp(e, 0, atom_types - 1)  # Ensure indices are within valid range\n",
    "\n",
    "    # Embedding\n",
    "    embedding_layer = nn.Embedding(num_embeddings=atom_types, embedding_dim=embedding_dim)\n",
    "    s = embedding_layer(e)\n",
    "\n",
    "    return (s, r), y.numpy()[13]  # Select attribute at index 13\n",
    "\n",
    "\n",
    "#\n",
    "def x2e(x, cutoff_distance=5.0):\n",
    "    \"\"\"convert xyz coordinates to pairwise distance with a cutoff distance\"\"\"\n",
    "   # Calculate pairwise distances\n",
    "   # this calculates the norm\n",
    "    #r0 = (x- x[:, None, :]) #TODO: RIJ \n",
    "    r2 = torch.sqrt(((x - x[:, None, :])**2).sum(dim=-1))\n",
    "\n",
    "    # Create a mask for distances less than cutoff_distance\n",
    "    mask = (r2>0) & (r2 <= cutoff_distance)\n",
    "\n",
    "    # Use the mask to set values in the tensor\n",
    "    r_ij = torch.where(mask, r2, torch.zeros_like(r2))\n",
    "\n",
    "    # Generate edge index matrix\n",
    "    #edge_index = torch.nonzero(mask, as_tuple=False)\n",
    "\n",
    "    #edge_mask = (r2 > 0) & (r2 < cutoff_distance)\n",
    "    edge_indices = mask.nonzero(as_tuple=True)\n",
    "    edge_index = torch.stack(edge_indices)\n",
    "    #edge_index = edge_index.resize_(2,len(mask))\n",
    "\n",
    "    return r_ij, edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Index: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,\n",
      "          5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "          6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "          7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "          9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11,\n",
      "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12,\n",
      "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "         13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15,\n",
      "         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16,\n",
      "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 17,  0,  2,\n",
      "          3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  0,  1,  3,\n",
      "          4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  0,  1,  2,  4,\n",
      "          5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  0,  1,  2,  3,  5,\n",
      "          6,  7,  8,  9, 11, 12, 13, 14, 15, 16, 17,  0,  1,  2,  3,  4,  6,  7,\n",
      "          8,  9, 11, 12, 13, 14, 15, 16, 17,  0,  1,  2,  3,  4,  5,  7,  8,  9,\n",
      "         10, 11, 12, 13, 14, 15, 16, 17,  0,  1,  2,  3,  4,  5,  6,  8,  9, 10,\n",
      "         11, 12, 13, 14, 15, 16, 17,  0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11,\n",
      "         12, 13, 15, 16, 17,  0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13,\n",
      "         15, 16,  0,  1,  2,  3,  6,  7,  8,  9, 11, 12, 13, 15, 16,  0,  1,  2,\n",
      "          3,  4,  5,  6,  7,  8,  9, 10, 12, 13, 15, 16, 17,  0,  1,  2,  3,  4,\n",
      "          5,  6,  7,  8,  9, 10, 11, 13, 15, 16,  0,  1,  2,  3,  4,  5,  6,  7,\n",
      "          8,  9, 10, 11, 12, 14,  1,  2,  3,  4,  5,  6,  7, 13, 15, 16, 17,  0,\n",
      "          1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 16, 17,  0,  1,  2,\n",
      "          3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 17,  0,  1,  2,  3,  4,\n",
      "          5,  6,  7,  8, 11, 14, 15, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Assuming test_set is a list of data points\n",
    "for d in test_set:\n",
    "    (s, r_ij), y_raw = convert_record(d)\n",
    "\n",
    "for d in test_set:\n",
    "    (e, x), y = convert_record(d)\n",
    "    r2, edge_index, = x2e(x)\n",
    "    print(\"Edge Index:\", edge_index)\n",
    "    break  # To print only the first molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising the targets\n",
    "Is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize y values first and transform after prediction\n",
    "ys = [convert_record(d)[1] for d in train_set]\n",
    "train_ym = np.mean(ys)\n",
    "train_ys = np.std(ys)\n",
    "def transform_label(y):\n",
    "    return (y - train_ym) / train_ys\n",
    "def transform_prediction(y):\n",
    "    return y * train_ys + train_ym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Painn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Message block\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class phi(nn.Module):\n",
    "    def __init__(self, input_dim=128):\n",
    "        super().__init__()\n",
    "        activation_fn = nn.SiLU\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim, bias=True),\n",
    "            activation_fn(),\n",
    "            nn.Linear(input_dim, 384, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, s):\n",
    "        return self.net(s)\n",
    "\n",
    "class RBF(nn.Module):\n",
    "    def __init__(self, r_cut=5.0):\n",
    "        super().__init__()\n",
    "        self.r_cut = r_cut\n",
    "        self.n_values = torch.arange(1, 21, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, r_ij):\n",
    "        r_RBF_list = []\n",
    "\n",
    "        for n_value in self.n_values:\n",
    "            r_RBF_n = (torch.sin((n_value * 3.14 / self.r_cut) * r_ij)) / r_ij\n",
    "            r_RBF_list.append(r_RBF_n)\n",
    "\n",
    "        r_RBF = torch.stack(r_RBF_list, dim=1)\n",
    "        return r_RBF\n",
    "\n",
    "class F_cut(nn.Module):\n",
    "    def __init__(self, r_cut=5.0):\n",
    "        super().__init__()\n",
    "        self.r_cut = r_cut\n",
    "\n",
    "    def forward(self, r_ij):\n",
    "        f_c = 0.5 * torch.cos(torch.pi * r_ij / self.r_cut) + 1\n",
    "        return f_c\n",
    "\n",
    "class w(nn.Module):\n",
    "    def __init__(self, r_cut=5.0):\n",
    "        super().__init__()\n",
    "        self.RBF = RBF(r_cut)\n",
    "        self.F_cut = F_cut(r_cut)\n",
    "        self.net = nn.Linear(20, 384, bias=True)\n",
    "\n",
    "    def forward(self, r_ij):\n",
    "        New_RBF = self.RBF(r_ij)\n",
    "        New_F_cut = self.F_cut(r_ij).unsqueeze(1)\n",
    "        Total = New_RBF * New_F_cut\n",
    "        Output = self.net(Total)\n",
    "        return Output\n",
    "\n",
    "class MessageBlock(nn.Module):\n",
    "    def __init__(self, input_dim=128):\n",
    "        super().__init__()\n",
    "        self.phi = phi(input_dim)\n",
    "        self.w = w()\n",
    "        self.v_j = nn.Parameter(torch.zeros(input_dim))\n",
    "\n",
    "    def forward(self, v_j, s, r_ij):\n",
    "        output_phi = self.phi(s)\n",
    "        output_w = self.w(r_ij)\n",
    "        output_conv = output_phi * output_w\n",
    "        output_split = torch.chunk(output_conv, 3, dim=1)\n",
    "\n",
    "        output_v = output_split[0] * v_j  # Select the first 128 elements\n",
    "        delta_s_im = output_split[1]  # Select the next 128 elements\n",
    "        output_r = output_split[2] * (r_ij / r_ij)  # Select the last 128 elements #TODO: check norm\n",
    "\n",
    "        delta_s_im = torch.sum(delta_s_im, dim=1)\n",
    "        delta_v_im = torch.sum(output_v + output_r, dim=1)\n",
    "        s = s + delta_s_im\n",
    "        v_j = v_j + delta_v_im\n",
    "\n",
    "        return s, v_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tester data\n",
    "# epochs=1\n",
    "\n",
    "# for d in train_set:\n",
    "#     (s, r), y_raw = convert_record(d)\n",
    "#     y = transform_label(y_raw)\n",
    "#     r_ij, edge_index = x2e(r, 5.0)\n",
    "# v_j = torch.zeros(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4608e-01,  2.7426e+00, -1.6253e+00, -9.7112e+00, -2.0808e+01,\n",
      "        -2.3514e+00, -1.4425e+01,  2.2441e+00, -2.6890e+01, -2.9704e+01,\n",
      "        -1.5665e+01, -3.3358e+01, -4.9397e+01,  1.1444e+00, -2.9431e+00,\n",
      "        -4.8132e+01, -4.2424e-01, -2.6809e-01, -7.7309e+00, -3.9982e+00,\n",
      "         3.7736e+00,  3.1092e+00, -1.8872e+00, -2.6213e+00,  4.0493e+00,\n",
      "        -1.8539e+01, -1.7433e+00, -3.3481e+00,  1.5808e+00, -2.2385e+00,\n",
      "        -1.5833e+00, -6.9907e-01, -1.7092e+00,  2.0120e+00, -2.1965e+00,\n",
      "        -2.6842e+01,  8.6010e-02,  5.1544e+00, -2.0535e+00, -3.5799e+00,\n",
      "        -3.2320e+00, -3.2570e+01,  8.0692e-01, -9.5783e-01, -4.8513e+01,\n",
      "        -4.3839e+01, -2.7998e+00, -1.4361e+00, -2.8423e+01, -2.8552e+00,\n",
      "        -4.4985e+00, -2.4656e+00,  7.3003e-01, -9.3106e-01, -2.6579e+00,\n",
      "        -5.0036e+01, -5.9857e-01,  1.0094e-02, -6.7909e+00, -1.1996e+00,\n",
      "         3.8419e+00, -2.5724e-01, -9.8857e-01, -2.5924e+00,  3.8499e+00,\n",
      "        -8.6154e-01,  2.8915e+00, -3.7510e+01, -6.1251e+00,  9.5894e-01,\n",
      "        -2.3247e+00, -3.5686e-02,  2.4008e+00, -3.2784e+01, -3.0780e+01,\n",
      "        -3.3662e+00, -4.7542e+01, -1.1535e+01, -2.2097e+00,  9.6239e-02,\n",
      "         5.3070e+00,  4.0631e+00, -1.1124e+00, -2.2922e+01,  8.4855e-02,\n",
      "        -1.4297e+00, -2.4401e+00, -4.1626e+01,  1.2069e+00, -2.0420e+01,\n",
      "        -1.4594e+00, -3.5210e+01, -2.4848e+00,  2.7475e+00, -2.9918e+00,\n",
      "         3.8514e-01, -3.6764e-01,  2.5919e+00, -4.5155e+00, -2.6375e+00,\n",
      "         1.4342e+00, -2.6560e+01, -1.4363e+01, -2.3922e+00, -3.7068e+01,\n",
      "         4.4056e-01, -2.5145e+00, -1.9234e+01, -4.3624e+00, -6.6433e-01,\n",
      "         1.2570e+00,  1.8366e-01, -2.8254e+00, -2.8471e+01, -5.2727e-01,\n",
      "         4.0161e+00, -4.4174e+00, -6.4745e-01, -4.6888e+01,  8.2128e-01,\n",
      "        -1.3250e+00, -4.8200e-01, -1.5674e+00, -5.0018e+01,  1.0846e+00,\n",
      "        -1.9981e+00, -4.4917e+01, -4.4033e-01], grad_fn=<AddBackward0>) tensor([ 3.0532e+00, -1.8210e+00,  3.7567e+00,  4.2544e+00,  1.3784e+00,\n",
      "         6.2984e+00,  5.5244e+00,  5.2202e-01,  8.6985e-01,  1.6532e+00,\n",
      "         6.1311e+00, -6.9950e-01, -5.5542e+00,  1.2565e+00,  9.6413e-01,\n",
      "        -3.7567e+00,  4.6948e+00,  4.9524e+00,  3.4707e+00,  1.4000e-01,\n",
      "        -4.0645e+00, -3.5942e-01,  4.4093e+00,  2.3377e+00,  2.3119e-01,\n",
      "         2.8270e+00,  3.5615e+00,  5.4163e-01, -2.5714e-02, -1.0491e-01,\n",
      "         2.2947e+00,  2.4491e+00,  5.4479e-01, -2.3871e+00,  2.4745e+00,\n",
      "         5.5510e-01,  6.4046e+00, -1.1844e+00,  9.5132e-01,  1.3122e+00,\n",
      "         3.6015e+00, -1.6377e+00,  1.4588e+00,  6.4373e+00, -6.2808e+00,\n",
      "        -4.6812e+00,  2.3600e+00,  2.3978e+00,  1.2032e+00,  3.9989e+00,\n",
      "         1.4275e+00,  1.4286e+00,  8.2614e+00,  2.8577e+00,  3.2925e+00,\n",
      "        -6.9582e+00, -1.2740e-01,  7.2369e+00,  3.4832e+00,  4.5308e+00,\n",
      "        -3.1428e+00,  5.0978e+00,  2.0132e+00,  1.0535e+00, -2.6345e+00,\n",
      "         1.9680e+00, -1.1401e+00, -2.6120e+00,  3.5825e+00, -1.3609e+00,\n",
      "         5.8646e+00,  1.6270e+00, -2.3627e+00, -3.5939e-02,  5.1744e-01,\n",
      "         5.4383e+00, -4.1897e+00,  4.7043e+00,  7.7199e+00,  9.1236e-02,\n",
      "         5.0422e-03,  1.7709e+00,  4.6564e+00,  1.0871e+00,  2.6113e+00,\n",
      "         4.7508e+00,  5.9562e+00, -3.9300e+00, -6.6510e-01,  1.4523e+00,\n",
      "         1.9367e+00,  5.7276e-01, -1.4103e+00, -2.3351e+00,  2.7242e+00,\n",
      "         3.8153e+00,  7.2988e+00,  9.6306e-01,  2.3342e+00, -2.0351e+00,\n",
      "         1.9929e+00,  7.6942e-01,  3.1908e+00,  2.4422e+00, -3.1365e+00,\n",
      "         1.8881e+00,  2.6743e+00,  2.2510e+00,  7.1554e-01,  6.7690e+00,\n",
      "         1.9736e+00,  1.3973e+00,  1.9692e+00,  1.6725e-03, -6.1458e-01,\n",
      "        -1.3929e+00,  1.5934e+00,  1.3003e+00, -5.1893e+00,  4.6292e-01,\n",
      "         1.5729e+00,  4.6034e+00, -3.3691e-01, -6.6767e+00,  4.3123e+00,\n",
      "         2.0680e-01, -6.1207e+00,  6.9819e+00], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# tester messageblock\n",
    "\n",
    "#MessageBlock(v_j, s, r_ij)\n",
    "v_j = torch.randn(128)\n",
    "s = torch.randn(128)\n",
    "r_ij = torch.randn(128)\n",
    "\n",
    "s, v_j = MessageBlock(input_dim=128).forward(v_j, s, r_ij)\n",
    "\n",
    "print(s, v_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update block\n",
    "\n",
    "class u(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(128, 128,bias=False)\n",
    "\n",
    "    def forward(self, v_j):\n",
    "        u_m = self.net(v_j)\n",
    "        return u_m\n",
    "\n",
    "\n",
    "class v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(128, 128,bias=False)\n",
    "\n",
    "    def forward(self, v_j):\n",
    "        v_m = self.net(v_j)\n",
    "        return v_m\n",
    "\n",
    "\n",
    "class S(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        activation_fn = nn.SiLU()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            activation_fn,\n",
    "            nn.Linear(128, 384)\n",
    "        )\n",
    "\n",
    "    def forward(self, v_m, s):\n",
    "        stack = torch.stack((torch.norm(v_m), s)) #TODO: stacking of a norm and a tensor?\n",
    "        output = self.net(stack)\n",
    "        return output\n",
    "\n",
    "\n",
    "class UpdateBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.s_m, self.v_m = MessageBlock() # Kat har added\n",
    "        self.u = u()\n",
    "        self.v = v()\n",
    "        self.s = S()\n",
    "\n",
    "    def forward(self, v_m, s):\n",
    "        output_u = self.u(v_m)\n",
    "        output_v = self.v(v_m)\n",
    "        output_s = self.s(v_m, s)\n",
    "\n",
    "        output_s = torch.chunk(output_s, 3, dim=1)\n",
    "        V_dup = output_v.repeat(1, 2)  # Assuming v_m has shape (batch_size, 128)\n",
    "        output_s1 = output_s[0] * output_u\n",
    "        output_s2 = output_s[1] * V_dup.squeeze(1)\n",
    "        output_s3 = output_s[2] + output_s2\n",
    "\n",
    "        delta_v_iu = output_s1\n",
    "        delta_s_iu = output_s2 + output_s3\n",
    "        # TODO: replace these with edge indexes from x2e\n",
    "        # atom i will be updated as a function of it's j neighbors (atom j)\n",
    "\n",
    "        return delta_v_iu, delta_s_iu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [] at entry 0 and [128] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\Simon_Tester_GNN.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m s \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m128\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m v_m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m128\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m delta_v_iu, delta_s_iu \u001b[39m=\u001b[39m UpdateBlock()\u001b[39m.\u001b[39;49mforward(v_m,s) \u001b[39m#TODO: modellen kan ikke finde v_m og s_m eftersom de ikker defineret endnu\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(delta_s_im,delta_v_im)\n",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\Simon_Tester_GNN.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m output_u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu(v_m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m output_v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv(v_m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m output_s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ms(v_m, s)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m output_s \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mchunk(output_s, \u001b[39m3\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m V_dup \u001b[39m=\u001b[39m output_v\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# Assuming v_m has shape (batch_size, 128)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\Simon_Tester_GNN.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, v_m, s):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     stack \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack((torch\u001b[39m.\u001b[39;49mnorm(v_m), s)) \u001b[39m#TODO: stacking of a norm and a tensor?\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet(stack)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/Simon_Tester_GNN.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [] at entry 0 and [128] at entry 1"
     ]
    }
   ],
   "source": [
    "#Testing update block\n",
    "\n",
    "s = torch.randn(128)\n",
    "v_m = torch.randn(128)\n",
    "\n",
    "delta_v_iu, delta_s_iu = UpdateBlock().forward(v_m,s) #TODO: modellen kan ikke finde v_m og s_m eftersom de ikker defineret endnu\n",
    "\n",
    "print(delta_s_im,delta_v_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Painn model\n",
    "\n",
    "Not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final PAINN model\n",
    "\n",
    "# TODO: fix painn modellen\n",
    "# KAT her\n",
    "\n",
    "class PaiNN(nn.Module):\n",
    "    def __init__(self, message_block, update_block):\n",
    "        super().__init__()\n",
    "        self.message_block = message_block\n",
    "        self.update_block = update_block\n",
    "\n",
    "    def forward(self, v_j, s, r_ij, num_iterations):\n",
    "        for _ in range(num_iterations):\n",
    "            # Message block\n",
    "            output1 = self.message_block.phi(s_j)\n",
    "            output2 = self.message_block.w(r_ij)\n",
    "            output = output1 * output2\n",
    "            output_split = torch.split(output, 3, dim=1)\n",
    "\n",
    "            # Update s_m\n",
    "            s_m = torch.sum(output_split[1], dim=1, keepdim=True) + s_j\n",
    "\n",
    "            # Update v_m\n",
    "            output3 = output_split[2] * v_norm\n",
    "            v_m = torch.sum(output3, dim=1, keepdim=True) + v_j\n",
    "\n",
    "\n",
    "            v_i = output_s1 + v_j\n",
    "            s_i = output_s3 + s_j\n",
    "\n",
    "            # Update variables for the next iteration\n",
    "            s_j = s_i\n",
    "            v_j = v_i\n",
    "\n",
    "        # The final v_i and s_i after all iterations\n",
    "        return v_i, s_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final PAINN model - Katrine\n",
    "\n",
    "\n",
    "class PaiNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.message_block = MessageBlock()\n",
    "        self.update_block = UpdateBlock()\n",
    "\n",
    "\n",
    "class PaiNN(nn.Module):\n",
    "    def __init__(self, phi_input_size, r_ij, r_cut, v_m_size, s_m_size):\n",
    "        super().__init__()\n",
    "        self.message_block = MessageBlock(phi_input_size, r_ij, r_cut)\n",
    "        self.update_block = UpdateBlock(v_m_size, s_m_size)\n",
    "\n",
    "\n",
    "    def forward(self, input1, input2, v_j, s, v_norm):\n",
    "        # Forward pass through the message block\n",
    "        v_m, s_m = self.message_block(input1, input2, v_j, s, v_norm)\n",
    "\n",
    "        # Forward pass through the update block\n",
    "        v_u, s_u = self.update_block(v_m, v_m, s_m, v_m, s_m)\n",
    "\n",
    "        # Return the updated values\n",
    "        return v_u, s_u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to iterate through the data\n",
    "eta = 1e-3\n",
    "val_loss = [0.0 for _ in range(epochs)]\n",
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    for d in train_set:\n",
    "        (e, x), y_raw = convert_record(d)\n",
    "        y = transform_label(y_raw)\n",
    "        grad = loss_grad(e, x, y, w1, w2, w3, b)\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: Look at this, this is made by the chat\n",
    "        # update regression weights\n",
    "        w3 -= eta * grad[2]\n",
    "        b -= eta * grad[3]\n",
    "        # update GNN weights\n",
    "        for i, w in [(0, w1), (1, w2)]:\n",
    "            for j in range(len(w)):\n",
    "                w[j] -= eta * grad[i][j] / 10\n",
    "    # compute validation loss\n",
    "    for v in valid_set:\n",
    "        (e, x), y_raw = convert_record(v)\n",
    "        y = transform_label(y_raw)\n",
    "        # convert SE to RMSE\n",
    "        val_loss[epoch] += loss(e, x, y, w1, w2, w3, b)\n",
    "    val_loss[epoch] = jnp.sqrt(val_loss[epoch] / 1000)\n",
    "    eta *= 0.9\n",
    "plt.plot(baseline_val_loss, label=\"baseline\")\n",
    "plt.plot(val_loss, label=\"GNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Val Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "yhats = []\n",
    "for v in valid_set:\n",
    "    (e, x), y = convert_record(v)\n",
    "    ys.append(y)\n",
    "    yhat_raw = model(e, x, w1, w2, w3, b)\n",
    "    yhats.append(transform_prediction(yhat_raw))\n",
    "\n",
    "\n",
    "plt.plot(ys, ys, \"-\")\n",
    "plt.plot(ys, yhats, \".\")\n",
    "plt.xlabel(\"Energy\")\n",
    "plt.ylabel(\"Predicted Energy\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
