{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing record file, delete if you want to re-fetch\n"
     ]
    }
   ],
   "source": [
    "#Import functions and load data\n",
    "import os\n",
    "os.chdir(\"../src\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dataloader import qm9_parse, qm9_fetch\n",
    "import dmol\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "qm9_records = qm9_fetch()\n",
    "data = qm9_parse(qm9_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take samples for test, validation and training\n",
    "shuffled_data = data.shuffle(7000, reshuffle_each_iteration=False)\n",
    "test_set = shuffled_data.take(1000)\n",
    "valid_set = shuffled_data.skip(1000).take(1000)\n",
    "train_set = shuffled_data.skip(2000).take(5000)\n",
    "\n",
    "# for d in test_set:\n",
    "#     print(d)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convert_record(d, atom_types=100, embedding_dim=128):\n",
    "    # break up record\n",
    "    (e, x), y = d\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    e = torch.tensor(e.numpy())\n",
    "    x = torch.tensor(x.numpy())\n",
    "    r = x[:, :3]\n",
    "\n",
    "    # Assuming atom indices start from 1\n",
    "    e = e - 1\n",
    "    e = torch.clamp(e, 0, atom_types - 1)  # Ensure indices are within valid range\n",
    "        \n",
    "    # Embedding\n",
    "    embedding_layer = nn.Embedding(num_embeddings=atom_types, embedding_dim=embedding_dim)\n",
    "    atom_embedding = embedding_layer(e)\n",
    "    \n",
    "    return (atom_embedding, r), y.numpy()[13]  # Select attribute at index 13\n",
    "\n",
    "def x2e(x, cutoff_distance=5.0):\n",
    "    \"\"\"convert xyz coordinates to pairwise distance with a cutoff distance\"\"\"\n",
    "   # Calculate pairwise distances\n",
    "    r2 = torch.sqrt(((x - x[:, None, :])**2).sum(dim=-1))\n",
    "    \n",
    "    # Create a mask for distances less than cutoff_distance\n",
    "    mask = r2 < cutoff_distance\n",
    "    \n",
    "    # Use the mask to set values in the tensor\n",
    "    e = torch.where(mask, r2, torch.zeros_like(r2))\n",
    "    \n",
    "    # Generate edge index matrix\n",
    "    edge_index = torch.nonzero(mask, as_tuple=False)\n",
    "    \n",
    "    return e, edge_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-417.09424\n",
      "Edge Index: tensor([[ 0,  0],\n",
      "        [ 0,  1],\n",
      "        [ 0,  2],\n",
      "        [ 0,  3],\n",
      "        [ 0,  4],\n",
      "        [ 0,  5],\n",
      "        [ 0,  6],\n",
      "        [ 0,  7],\n",
      "        [ 0,  8],\n",
      "        [ 0,  9],\n",
      "        [ 0, 10],\n",
      "        [ 0, 11],\n",
      "        [ 0, 12],\n",
      "        [ 0, 13],\n",
      "        [ 0, 14],\n",
      "        [ 0, 15],\n",
      "        [ 1,  0],\n",
      "        [ 1,  1],\n",
      "        [ 1,  2],\n",
      "        [ 1,  3],\n",
      "        [ 1,  4],\n",
      "        [ 1,  5],\n",
      "        [ 1,  6],\n",
      "        [ 1,  7],\n",
      "        [ 1,  8],\n",
      "        [ 1,  9],\n",
      "        [ 1, 10],\n",
      "        [ 1, 11],\n",
      "        [ 1, 12],\n",
      "        [ 1, 13],\n",
      "        [ 1, 14],\n",
      "        [ 1, 15],\n",
      "        [ 2,  0],\n",
      "        [ 2,  1],\n",
      "        [ 2,  2],\n",
      "        [ 2,  3],\n",
      "        [ 2,  4],\n",
      "        [ 2,  5],\n",
      "        [ 2,  6],\n",
      "        [ 2,  7],\n",
      "        [ 2,  8],\n",
      "        [ 2,  9],\n",
      "        [ 2, 10],\n",
      "        [ 2, 11],\n",
      "        [ 2, 12],\n",
      "        [ 2, 13],\n",
      "        [ 2, 14],\n",
      "        [ 2, 15],\n",
      "        [ 3,  0],\n",
      "        [ 3,  1],\n",
      "        [ 3,  2],\n",
      "        [ 3,  3],\n",
      "        [ 3,  4],\n",
      "        [ 3,  5],\n",
      "        [ 3,  6],\n",
      "        [ 3,  7],\n",
      "        [ 3,  8],\n",
      "        [ 3,  9],\n",
      "        [ 3, 10],\n",
      "        [ 3, 11],\n",
      "        [ 3, 12],\n",
      "        [ 3, 13],\n",
      "        [ 3, 14],\n",
      "        [ 3, 15],\n",
      "        [ 4,  0],\n",
      "        [ 4,  1],\n",
      "        [ 4,  2],\n",
      "        [ 4,  3],\n",
      "        [ 4,  4],\n",
      "        [ 4,  5],\n",
      "        [ 4,  6],\n",
      "        [ 4,  7],\n",
      "        [ 4,  8],\n",
      "        [ 4,  9],\n",
      "        [ 4, 10],\n",
      "        [ 4, 11],\n",
      "        [ 4, 12],\n",
      "        [ 4, 13],\n",
      "        [ 4, 14],\n",
      "        [ 4, 15],\n",
      "        [ 5,  0],\n",
      "        [ 5,  1],\n",
      "        [ 5,  2],\n",
      "        [ 5,  3],\n",
      "        [ 5,  4],\n",
      "        [ 5,  5],\n",
      "        [ 5,  6],\n",
      "        [ 5,  7],\n",
      "        [ 5,  8],\n",
      "        [ 5,  9],\n",
      "        [ 5, 10],\n",
      "        [ 5, 11],\n",
      "        [ 5, 12],\n",
      "        [ 5, 13],\n",
      "        [ 5, 14],\n",
      "        [ 5, 15],\n",
      "        [ 6,  0],\n",
      "        [ 6,  1],\n",
      "        [ 6,  2],\n",
      "        [ 6,  3],\n",
      "        [ 6,  4],\n",
      "        [ 6,  5],\n",
      "        [ 6,  6],\n",
      "        [ 6,  7],\n",
      "        [ 6,  8],\n",
      "        [ 6,  9],\n",
      "        [ 6, 10],\n",
      "        [ 6, 11],\n",
      "        [ 6, 12],\n",
      "        [ 6, 13],\n",
      "        [ 6, 14],\n",
      "        [ 6, 15],\n",
      "        [ 7,  0],\n",
      "        [ 7,  1],\n",
      "        [ 7,  2],\n",
      "        [ 7,  3],\n",
      "        [ 7,  4],\n",
      "        [ 7,  5],\n",
      "        [ 7,  6],\n",
      "        [ 7,  7],\n",
      "        [ 7,  8],\n",
      "        [ 7,  9],\n",
      "        [ 7, 10],\n",
      "        [ 7, 11],\n",
      "        [ 7, 12],\n",
      "        [ 7, 14],\n",
      "        [ 7, 15],\n",
      "        [ 8,  0],\n",
      "        [ 8,  1],\n",
      "        [ 8,  2],\n",
      "        [ 8,  3],\n",
      "        [ 8,  4],\n",
      "        [ 8,  5],\n",
      "        [ 8,  6],\n",
      "        [ 8,  7],\n",
      "        [ 8,  8],\n",
      "        [ 8,  9],\n",
      "        [ 8, 10],\n",
      "        [ 8, 11],\n",
      "        [ 8, 12],\n",
      "        [ 8, 14],\n",
      "        [ 8, 15],\n",
      "        [ 9,  0],\n",
      "        [ 9,  1],\n",
      "        [ 9,  2],\n",
      "        [ 9,  3],\n",
      "        [ 9,  4],\n",
      "        [ 9,  5],\n",
      "        [ 9,  6],\n",
      "        [ 9,  7],\n",
      "        [ 9,  8],\n",
      "        [ 9,  9],\n",
      "        [ 9, 10],\n",
      "        [ 9, 11],\n",
      "        [ 9, 12],\n",
      "        [ 9, 13],\n",
      "        [ 9, 14],\n",
      "        [ 9, 15],\n",
      "        [10,  0],\n",
      "        [10,  1],\n",
      "        [10,  2],\n",
      "        [10,  3],\n",
      "        [10,  4],\n",
      "        [10,  5],\n",
      "        [10,  6],\n",
      "        [10,  7],\n",
      "        [10,  8],\n",
      "        [10,  9],\n",
      "        [10, 10],\n",
      "        [10, 11],\n",
      "        [10, 12],\n",
      "        [10, 13],\n",
      "        [10, 14],\n",
      "        [10, 15],\n",
      "        [11,  0],\n",
      "        [11,  1],\n",
      "        [11,  2],\n",
      "        [11,  3],\n",
      "        [11,  4],\n",
      "        [11,  5],\n",
      "        [11,  6],\n",
      "        [11,  7],\n",
      "        [11,  8],\n",
      "        [11,  9],\n",
      "        [11, 10],\n",
      "        [11, 11],\n",
      "        [11, 12],\n",
      "        [11, 13],\n",
      "        [11, 14],\n",
      "        [11, 15],\n",
      "        [12,  0],\n",
      "        [12,  1],\n",
      "        [12,  2],\n",
      "        [12,  3],\n",
      "        [12,  4],\n",
      "        [12,  5],\n",
      "        [12,  6],\n",
      "        [12,  7],\n",
      "        [12,  8],\n",
      "        [12,  9],\n",
      "        [12, 10],\n",
      "        [12, 11],\n",
      "        [12, 12],\n",
      "        [12, 13],\n",
      "        [12, 14],\n",
      "        [12, 15],\n",
      "        [13,  0],\n",
      "        [13,  1],\n",
      "        [13,  2],\n",
      "        [13,  3],\n",
      "        [13,  4],\n",
      "        [13,  5],\n",
      "        [13,  6],\n",
      "        [13,  9],\n",
      "        [13, 10],\n",
      "        [13, 11],\n",
      "        [13, 12],\n",
      "        [13, 13],\n",
      "        [13, 14],\n",
      "        [13, 15],\n",
      "        [14,  0],\n",
      "        [14,  1],\n",
      "        [14,  2],\n",
      "        [14,  3],\n",
      "        [14,  4],\n",
      "        [14,  5],\n",
      "        [14,  6],\n",
      "        [14,  7],\n",
      "        [14,  8],\n",
      "        [14,  9],\n",
      "        [14, 10],\n",
      "        [14, 11],\n",
      "        [14, 12],\n",
      "        [14, 13],\n",
      "        [14, 14],\n",
      "        [14, 15],\n",
      "        [15,  0],\n",
      "        [15,  1],\n",
      "        [15,  2],\n",
      "        [15,  3],\n",
      "        [15,  4],\n",
      "        [15,  5],\n",
      "        [15,  6],\n",
      "        [15,  7],\n",
      "        [15,  8],\n",
      "        [15,  9],\n",
      "        [15, 10],\n",
      "        [15, 11],\n",
      "        [15, 12],\n",
      "        [15, 13],\n",
      "        [15, 14],\n",
      "        [15, 15]])\n"
     ]
    }
   ],
   "source": [
    "# Assuming test_set is a list of data points\n",
    "for d in test_set:\n",
    "    (e, x), y_raw = convert_record(d)\n",
    "\n",
    "print(y_raw)\n",
    "nodes = e\n",
    "edges = x2e(x)\n",
    "\n",
    "for d in test_set:\n",
    "    (e, x), y = convert_record(d)\n",
    "    r2, edge_index = x2e(x)\n",
    "    print(\"Edge Index:\", edge_index)\n",
    "    break  # To print only the first molecule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize y values first and transform after prediction\n",
    "ys = [convert_record(d)[1] for d in train_set]\n",
    "train_ym = np.mean(ys)\n",
    "train_ys = np.std(ys)\n",
    "def transform_label(y):\n",
    "    return (y - train_ym) / train_ys\n",
    "def transform_prediction(y):\n",
    "    return y * train_ys + train_ym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAINN model\n",
    "\n",
    "from typing import Callable, Dict, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import schnetpack.properties as properties\n",
    "import schnetpack.nn as snn\n",
    "\n",
    "__all__ = [\"phi\", \"w\", \"u\", \"v\",\"s\", \"PaiNN\"]\n",
    "\n",
    "\n",
    "# v_norm = r_ij/torch.sqrt(torch.sum(r_ij**2))\n",
    "\n",
    "# v_j = torch.zeros(128)\n",
    "\n",
    "class phi(nn.Module):\n",
    "\n",
    "     def __init__(self,input_dim=128):\n",
    "        super().__init__()\n",
    "        self.input_dim=input_dim\n",
    "        activation_fn = nn.SiLU\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 128),\n",
    "            activation_fn(),\n",
    "            nn.Linear(128, 384),\n",
    "        )\n",
    "    def forward(self,s_j):\n",
    "        return self.net(s_j)\n",
    "\n",
    "class RBF(nn.Module):\n",
    "    def __init__(self,r_cut=5.0):\n",
    "        self.r_cut = r_cut\n",
    "        self.n_values = torch.arange(1, 21, dtype=torch.float32)\n",
    "    def forward(self,r_ij):\n",
    "        r_RBF = torch.sin((self.n_values*torch.pi()/self.r_cut)*r_ij)/r_ij\n",
    "        return r_RBF\n",
    "\n",
    "class F_cut(nn.Module):\n",
    "    def __init__(self,r_cut=5.0):\n",
    "        self.r_cut = r_cut\n",
    "    def forward(self,r_ij):\n",
    "        f_c=0.5*torch.cos(torch.pi()*r_ij/self.r_cut)+1\n",
    "        return f_c\n",
    "\n",
    "class w(nn.Module):\n",
    "    def __init__(self,r_ij,r_cut):\n",
    "        super().__init__()\n",
    "        self.r_ij = r_ij\n",
    "        self.r_cut = r_cut\n",
    "\n",
    "        self.RBF=RBF(r_cut=5.0)\n",
    "        self.F_cut=F_cut(r_cut=5.0)\n",
    "        self.net = nn.Linear(20,384)\n",
    "\n",
    "    def forward(self,r_ij):\n",
    "        New_RBF = self.RBF(r_ij)\n",
    "        New_F_cut=self.F_cut(r_ij)\n",
    "        Total = New_RBF*New_F_cut\n",
    "        Output=self.net(Total)\n",
    "        return Output\n",
    "    \n",
    "\n",
    "class MessageBlock(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.phi = phi(input_dim=128)\n",
    "        self.w = w(r_ij=None, r_cut=5.0)  # Initialize w with r_ij=None\n",
    "\n",
    "    def forward(self, s_j, r_ij, v_j, v_norm):\n",
    "        output1 = self.phi(s_j)\n",
    "        output2 = self.w(r_ij)\n",
    "        output = output1 * output2\n",
    "        output_split = torch.split(output, 3, dim=1)  # Split along the second dimension\n",
    "\n",
    "        # Update s_m\n",
    "        s_m = torch.sum(output_split[1], dim=1, keepdim=True) + s_j\n",
    "\n",
    "        # Update v_m\n",
    "        output3 = output_split[2] * v_norm\n",
    "        v_m = torch.sum(output3, dim=1, keepdim=True) + v_j\n",
    "\n",
    "        return s_m, v_m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update block\n",
    "\n",
    "class u(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(128, 128)\n",
    "\n",
    "    def forward(self, v_m):\n",
    "        return self.net(v_m)\n",
    "\n",
    "\n",
    "class v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(128, 128)\n",
    "\n",
    "    def forward(self, v_m):\n",
    "        return self.net(v_m)\n",
    "\n",
    "\n",
    "class S(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(S, self).__init__()\n",
    "        activation_fn = nn.SiLU()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            activation_fn,\n",
    "            nn.Linear(128, 384)\n",
    "        )\n",
    "\n",
    "    def forward(self, v_norm, s_m):\n",
    "        stack = torch.stack((v_norm, s_m))\n",
    "        output = self.net(stack)\n",
    "        output = torch.split(output, 128)\n",
    "        return output\n",
    "\n",
    "\n",
    "class UpdateBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.u = u()\n",
    "        self.v = v()\n",
    "        self.s = S()\n",
    "\n",
    "    def forward(self, v_m, v_j, s_j, s_m):\n",
    "        output_u = self.u(v_m)\n",
    "        output_v = self.v(v_m)\n",
    "        output_s = self.s(v_norm=s_m, s_m=s_j)\n",
    "        \n",
    "        V_dup = output_v.repeat(1, 2)  # Assuming v_m has shape (batch_size, 128)\n",
    "        output_s1 = output_s[0] * output_u\n",
    "        output_s2 = output_s[1] * V_dup\n",
    "        output_s3 = output_s[2] + output_s2\n",
    "\n",
    "        v_i = output_s1 + v_j\n",
    "        s_i = output_s3 + s_j\n",
    "\n",
    "        return v_i, s_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final PAINN model\n",
    "\n",
    "class PaiNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.message_block = MessageBlock()\n",
    "        self.update_block = UpdateBlock()\n",
    "\n",
    "        # You may need to define an initial input, for example, s_j, r_ij, v_j, and v_norm\n",
    "        # Replace the following with your actual initialization logic\n",
    "        self.initial_s_j = torch.zeros((batch_size, 128))\n",
    "        self.initial_r_ij = torch.zeros((batch_size, 3))\n",
    "        self.initial_v_j = torch.zeros((batch_size, 128))\n",
    "        self.initial_v_norm = torch.zeros((batch_size, 3))\n",
    "\n",
    "    def forward(self, num_iterations):\n",
    "        # Initialize variables\n",
    "        s_j = self.initial_s_j\n",
    "        r_ij = self.initial_r_ij\n",
    "        v_j = self.initial_v_j\n",
    "        v_norm = self.initial_v_norm\n",
    "\n",
    "        for _ in range(num_iterations):\n",
    "            # Message block\n",
    "            output1 = self.message_block.phi(s_j)\n",
    "            output2 = self.message_block.w(r_ij)\n",
    "            output = output1 * output2\n",
    "            output_split = torch.split(output, 3, dim=1)\n",
    "\n",
    "            # Update s_m\n",
    "            s_m = torch.sum(output_split[1], dim=1, keepdim=True) + s_j\n",
    "\n",
    "            # Update v_m\n",
    "            output3 = output_split[2] * v_norm\n",
    "            v_m = torch.sum(output3, dim=1, keepdim=True) + v_j\n",
    "\n",
    "            # Update block\n",
    "            output_u = self.update_block.u(v_m)\n",
    "            output_v = self.update_block.v(v_m)\n",
    "            output_s = self.update_block.s(v_norm=s_m, s_m=s_j)\n",
    "\n",
    "            V_dup = output_v.repeat(1, 2)\n",
    "            output_s1 = output_s[0] * output_u\n",
    "            output_s2 = output_s[1] * V_dup\n",
    "            output_s3 = output_s[2] + output_s2\n",
    "\n",
    "            v_i = output_s1 + v_j\n",
    "            s_i = output_s3 + s_j\n",
    "\n",
    "            # Update variables for the next iteration\n",
    "            s_j = s_i\n",
    "            v_j = v_i\n",
    "\n",
    "        # The final v_i and s_i after all iterations\n",
    "        return v_i, s_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to iterate through the data\n",
    "eta = 1e-3\n",
    "val_loss = [0.0 for _ in range(epochs)]\n",
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    for d in train_set:\n",
    "        (e, x), y_raw = convert_record(d)\n",
    "        y = transform_label(y_raw)\n",
    "        grad = loss_grad(e, x, y, w1, w2, w3, b)\n",
    "        # update regression weights\n",
    "        w3 -= eta * grad[2]\n",
    "        b -= eta * grad[3]\n",
    "        # update GNN weights\n",
    "        for i, w in [(0, w1), (1, w2)]:\n",
    "            for j in range(len(w)):\n",
    "                w[j] -= eta * grad[i][j] / 10\n",
    "    # compute validation loss\n",
    "    for v in valid_set:\n",
    "        (e, x), y_raw = convert_record(v)\n",
    "        y = transform_label(y_raw)\n",
    "        # convert SE to RMSE\n",
    "        val_loss[epoch] += loss(e, x, y, w1, w2, w3, b)\n",
    "    val_loss[epoch] = jnp.sqrt(val_loss[epoch] / 1000)\n",
    "    eta *= 0.9\n",
    "plt.plot(baseline_val_loss, label=\"baseline\")\n",
    "plt.plot(val_loss, label=\"GNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Val Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "yhats = []\n",
    "for v in valid_set:\n",
    "    (e, x), y = convert_record(v)\n",
    "    ys.append(y)\n",
    "    yhat_raw = model(e, x, w1, w2, w3, b)\n",
    "    yhats.append(transform_prediction(yhat_raw))\n",
    "\n",
    "\n",
    "plt.plot(ys, ys, \"-\")\n",
    "plt.plot(ys, yhats, \".\")\n",
    "plt.xlabel(\"Energy\")\n",
    "plt.ylabel(\"Predicted Energy\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
