{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset,\n",
    "    download_url,\n",
    "    extract_zip,\n",
    ")\n",
    "from torch_geometric.utils import one_hot, scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM9(InMemoryDataset):\n",
    "    raw_url = ('https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/'\n",
    "                'molnet_publish/qm9.zip')\n",
    "    raw_url2 = 'https://ndownloader.figshare.com/files/3195404'\n",
    "    processed_url = 'https://data.pyg.org/datasets/qm9_v3.zip'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "    ):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter,\n",
    "                        force_reload=force_reload)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    def mean(self, target: int) -> float:\n",
    "        y = torch.cat([self.get(i).y for i in range(len(self))], dim=0)\n",
    "        return float(y[:, target].mean())\n",
    "\n",
    "    def std(self, target: int) -> float:\n",
    "        y = torch.cat([self.get(i).y for i in range(len(self))], dim=0)\n",
    "        return float(y[:, target].std())\n",
    "\n",
    "    def atomref(self, target) -> Optional[torch.Tensor]:\n",
    "        if target in atomrefs:\n",
    "            out = torch.zeros(100)\n",
    "            out[torch.tensor([1, 6, 7, 8, 9])] = torch.tensor(atomrefs[target])\n",
    "            return out.view(-1, 1)\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        try:\n",
    "            import rdkit  # noqa\n",
    "            return ['gdb9.sdf', 'gdb9.sdf.csv', 'uncharacterized.txt']\n",
    "        except ImportError:\n",
    "            return ['qm9_v3.pt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data_v3.pt'\n",
    "\n",
    "    def download(self):\n",
    "        try:\n",
    "            import rdkit  # noqa\n",
    "            file_path = download_url(self.raw_url, self.raw_dir)\n",
    "            extract_zip(file_path, self.raw_dir)\n",
    "            os.unlink(file_path)\n",
    "\n",
    "            file_path = download_url(self.raw_url2, self.raw_dir)\n",
    "            os.rename(osp.join(self.raw_dir, '3195404'),\n",
    "                    osp.join(self.raw_dir, 'uncharacterized.txt'))\n",
    "        except ImportError:\n",
    "            path = download_url(self.processed_url, self.raw_dir)\n",
    "            extract_zip(path, self.raw_dir)\n",
    "            os.unlink(path)\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            import rdkit\n",
    "            from rdkit import Chem, RDLogger\n",
    "            from rdkit.Chem.rdchem import BondType as BT\n",
    "            from rdkit.Chem.rdchem import HybridizationType\n",
    "            RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "        except ImportError:\n",
    "            rdkit = None\n",
    "\n",
    "        if rdkit is None:\n",
    "            print((\"Using a pre-processed version of the dataset. Please \"\n",
    "                \"install 'rdkit' to alternatively process the raw data.\"),\n",
    "                file=sys.stderr)\n",
    "\n",
    "            data_list = torch.load(self.raw_paths[0])\n",
    "            data_list = [Data(**data_dict) for data_dict in data_list]\n",
    "\n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "            self.save(data_list, self.processed_paths[0])\n",
    "            return\n",
    "\n",
    "        types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\n",
    "        bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
    "\n",
    "        with open(self.raw_paths[1], 'r') as f:\n",
    "            target = f.read().split('\\n')[1:-1]\n",
    "            target = [[float(x) for x in line.split(',')[1:20]]\n",
    "                    for line in target]\n",
    "            target = torch.tensor(target, dtype=torch.float)\n",
    "            target = torch.cat([target[:, 3:], target[:, :3]], dim=-1)\n",
    "            target = target * conversion.view(1, -1)\n",
    "\n",
    "        with open(self.raw_paths[2], 'r') as f:\n",
    "            skip = [int(x.split()[0]) - 1 for x in f.read().split('\\n')[9:-2]]\n",
    "\n",
    "        suppl = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False,\n",
    "                                sanitize=False)\n",
    "\n",
    "        data_list = []\n",
    "        for i, mol in enumerate(tqdm(suppl)):\n",
    "            if i in skip:\n",
    "                continue\n",
    "\n",
    "            N = mol.GetNumAtoms()\n",
    "\n",
    "            conf = mol.GetConformer()\n",
    "            pos = conf.GetPositions()\n",
    "            pos = torch.tensor(pos, dtype=torch.float)\n",
    "\n",
    "            type_idx = []\n",
    "            atomic_number = []\n",
    "            aromatic = []\n",
    "            sp = []\n",
    "            sp2 = []\n",
    "            sp3 = []\n",
    "            num_hs = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                type_idx.append(types[atom.GetSymbol()])\n",
    "                atomic_number.append(atom.GetAtomicNum())\n",
    "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
    "                hybridization = atom.GetHybridization()\n",
    "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
    "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
    "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
    "\n",
    "            z = torch.tensor(atomic_number, dtype=torch.long)\n",
    "\n",
    "            row, col, edge_type = [], [], []\n",
    "            for bond in mol.GetBonds():\n",
    "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "                row += [start, end]\n",
    "                col += [end, start]\n",
    "                edge_type += 2 * [bonds[bond.GetBondType()]]\n",
    "\n",
    "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "            edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
    "            edge_attr = one_hot(edge_type, num_classes=len(bonds))\n",
    "\n",
    "            perm = (edge_index[0] * N + edge_index[1]).argsort()\n",
    "            edge_index = edge_index[:, perm]\n",
    "            edge_type = edge_type[perm]\n",
    "            edge_attr = edge_attr[perm]\n",
    "\n",
    "            row, col = edge_index\n",
    "            hs = (z == 1).to(torch.float)\n",
    "            num_hs = scatter(hs[row], col, dim_size=N, reduce='sum').tolist()\n",
    "\n",
    "            x1 = one_hot(torch.tensor(type_idx), num_classes=len(types))\n",
    "            x2 = torch.tensor([atomic_number, aromatic, sp, sp2, sp3, num_hs],\n",
    "                            dtype=torch.float).t().contiguous()\n",
    "            x = torch.cat([x1, x2], dim=-1)\n",
    "\n",
    "            y = target[i].unsqueeze(0)\n",
    "            name = mol.GetProp('_Name')\n",
    "            smiles = Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "\n",
    "            data = Data(\n",
    "                x=x,\n",
    "                z=z,\n",
    "                pos=pos,\n",
    "                edge_index=edge_index,\n",
    "                smiles=smiles,\n",
    "                edge_attr=edge_attr,\n",
    "                y=y,\n",
    "                name=name,\n",
    "                idx=i,\n",
    "            )\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecules in the training set: 1000\n",
      "Number of molecules in the test set: 1000\n",
      "Number of molecules in the validation set: 1000\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "\n",
    "# Set the root directory where the dataset will be stored\n",
    "root = \"your/root/directory\"\n",
    "\n",
    "# Instantiate the QM9 dataset\n",
    "dataset = QM9(root)\n",
    "\n",
    "# Limit the dataset to the first 3000 molecules\n",
    "dataset = dataset[:3000]\n",
    "\n",
    "# Split the dataset into training, testing, and validation sets\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [1000, 1000, 1000], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Print the number of molecules in each set\n",
    "print(f\"Number of molecules in the training set: {len(train_dataset)}\")\n",
    "print(f\"Number of molecules in the test set: {len(test_dataset)}\")\n",
    "print(f\"Number of molecules in the validation set: {len(val_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.data import Batch, Data, DataLoader\n",
    "from torch_geometric.nn import radius, radius_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F_cut & RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineCutoff(torch.nn.Module):\n",
    "    def __init__(self, cutoff=5.0):\n",
    "        super(CosineCutoff, self).__init__()\n",
    "        # self.register_buffer(\"cutoff\", torch.FloatTensor([cutoff]))\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def forward(self, distances):\n",
    "        \"\"\"Compute cutoff.\n",
    "\n",
    "        Args:\n",
    "            distances (torch.Tensor): values of interatomic distances.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: values of cutoff function.\n",
    "\n",
    "        \"\"\"\n",
    "        # Compute values of cutoff function\n",
    "        cutoffs = 0.5 * (torch.cos(distances * np.pi / self.cutoff) + 1.0)\n",
    "        # Remove contributions beyond the cutoff radius\n",
    "        cutoffs *= (distances < self.cutoff).float()\n",
    "        return cutoffs\n",
    "\n",
    "\n",
    "class BesselBasis(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Sine for radial basis expansion with coulomb decay. (0th order Bessel from DimeNet)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cutoff=5.0, n_rbf=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cutoff: radial cutoff\n",
    "            n_rbf: number of basis functions.\n",
    "        \"\"\"\n",
    "        super(BesselBasis, self).__init__()\n",
    "        # compute offset and width of Gaussian functions\n",
    "        freqs = torch.arange(1, n_rbf + 1) * math.pi / cutoff\n",
    "        self.register_buffer(\"freqs\", freqs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = torch.norm(inputs, p=2, dim=1)\n",
    "        a = self.freqs\n",
    "        ax = torch.outer(inputs, a)\n",
    "        sinax = torch.sin(ax)\n",
    "\n",
    "        norm = torch.where(inputs == 0, torch.tensor(1.0, device=inputs.device), inputs)\n",
    "        y = sinax / norm[:, None]\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class MessagePassPaiNN(MessagePassing):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20):\n",
    "        super(MessagePassPaiNN, self).__init__(aggr=\"add\")\n",
    "\n",
    "        self.lin1 = Linear(num_feat, out_channels)\n",
    "        self.lin2 = Linear(out_channels, 3 * out_channels)\n",
    "        self.lin_rbf = Linear(n_rbf, 3 * out_channels)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        self.RBF = BesselBasis(cut_off, n_rbf)\n",
    "        self.f_cut = CosineCutoff(cut_off)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_feat = num_feat\n",
    "\n",
    "    def forward(self, s, v, edge_index, edge_attr):\n",
    "\n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "\n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "\n",
    "        x = torch.cat([s, v], dim=-1)\n",
    "\n",
    "        x = self.propagate(\n",
    "            edge_index,\n",
    "            x=x,\n",
    "            edge_attr=edge_attr,\n",
    "            flat_shape_s=flat_shape_s,\n",
    "            flat_shape_v=flat_shape_v,\n",
    "        )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j, edge_attr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        # Split Input into s_j and v_j\n",
    "        s_j, v_j = torch.split(x_j, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        # r_ij channel\n",
    "        rbf = self.RBF(edge_attr)\n",
    "        ch1 = self.lin_rbf(rbf)\n",
    "        cut = self.f_cut(edge_attr.norm(dim=-1))\n",
    "        W = torch.einsum(\"ij,i->ij\", ch1, cut)  # ch1 * f_cut\n",
    "\n",
    "        # s_j channel\n",
    "        phi = self.lin1(s_j)\n",
    "        phi = self.silu(phi)\n",
    "        phi = self.lin2(phi)\n",
    "\n",
    "        # Split\n",
    "\n",
    "        left, dsm, right = torch.split(phi * W, self.num_feat, dim=-1)\n",
    "\n",
    "        # v_j channel\n",
    "        normalized = Func.normalize(edge_attr, p=2, dim=1)\n",
    "        v_j = v_j.reshape(-1, int(flat_shape_v / 3), 3)\n",
    "        hadamard_right = torch.einsum(\"ij,ik->ijk\", right, normalized)\n",
    "        hadamard_left = torch.einsum(\"ijk,ij->ijk\", v_j, left)\n",
    "        dvm = hadamard_left + hadamard_right\n",
    "\n",
    "        # Prepare vector for update\n",
    "        x_j = torch.cat((dsm, dvm.flatten(-2)), dim=-1)\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, out_aggr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        s_j, v_j = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        return s_j, v_j.reshape(-1, int(flat_shape_v / 3), 3)\n",
    "\n",
    "\n",
    "class MessagePassPaiNN_NE(MessagePassing):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20):\n",
    "        super(MessagePassPaiNN_NE, self).__init__(aggr=\"add\")\n",
    "\n",
    "        self.lin1 = Linear(num_feat, out_channels)\n",
    "        self.lin2 = Linear(out_channels, 3 * out_channels)\n",
    "        self.lin_rbf = Linear(n_rbf, 3 * out_channels)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        # self.prepare = Prepare_Message_Vector(num_nodes)\n",
    "        self.RBF = BesselBasis(cut_off, n_rbf)\n",
    "        self.f_cut = CosineCutoff(cut_off)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_feat = num_feat\n",
    "\n",
    "    def forward(self, s, v, s_nuc, v_nuc, edge_index, edge_attr):\n",
    "\n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "\n",
    "        s_nuc = s_nuc.flatten(-1)\n",
    "        v_nuc = v_nuc.flatten(-2)\n",
    "\n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "\n",
    "        n_nuc = s_nuc.shape[0]\n",
    "        n_elec = s.shape[0]\n",
    "\n",
    "        x_p = torch.cat([s_nuc, v_nuc], dim=-1)  # nuclei\n",
    "        x = torch.cat([s, v], dim=-1)  # electrons\n",
    "\n",
    "        x = self.propagate(\n",
    "            edge_index,\n",
    "            x=(x_p, x),\n",
    "            edge_attr=edge_attr,\n",
    "            flat_shape_s=flat_shape_s,\n",
    "            flat_shape_v=flat_shape_v,\n",
    "            size=(n_nuc, n_elec),\n",
    "        )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j, edge_attr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        # Split Input into s_j and v_j\n",
    "        s_j, v_j = torch.split(x_j, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "        # _, v_i = torch.split(x_i, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        # r_ij channel\n",
    "        rbf = self.RBF(edge_attr)\n",
    "        ch1 = self.lin_rbf(rbf)\n",
    "        cut = self.f_cut(edge_attr.norm(dim=-1))\n",
    "        W = torch.einsum(\"ij,i->ij\", ch1, cut)  # ch1 * f_cut\n",
    "\n",
    "        # s_j channel\n",
    "        phi = self.lin1(s_j)\n",
    "        phi = self.silu(phi)\n",
    "        phi = self.lin2(phi)\n",
    "\n",
    "        # Split\n",
    "        left, dsm, right = torch.split(phi * W, self.num_feat, dim=-1)\n",
    "\n",
    "        # v_j channel\n",
    "        normalized = Func.normalize(edge_attr, p=2, dim=1)\n",
    "\n",
    "        v_j = v_j.reshape(-1, int(flat_shape_v / 3), 3)\n",
    "        # v_i = v_i.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        # print(v_j - v_i)\n",
    "        hadamard_right = torch.einsum(\"ij,ik->ijk\", right, normalized)\n",
    "        hadamard_left = torch.einsum(\"ijk,ij->ijk\", v_j, left)\n",
    "        dvm = hadamard_left + hadamard_right\n",
    "\n",
    "        # Prepare vector for update\n",
    "        x_j = torch.cat((dsm, dvm.flatten(-2)), dim=-1)\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, out_aggr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        s_j, v_j = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        return s_j, v_j.reshape(-1, int(flat_shape_v / 3), 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatePaiNN(torch.nn.Module):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes):\n",
    "        super(UpdatePaiNN, self).__init__() \n",
    "        \n",
    "        self.lin_up = Linear(2*num_feat, out_channels) \n",
    "        self.denseU = Linear(num_feat,out_channels, bias = False) \n",
    "        self.denseV = Linear(num_feat,out_channels, bias = False) \n",
    "        self.lin2 = Linear(out_channels, 3*out_channels) \n",
    "        self.silu = Func.silu\n",
    "        \n",
    "        \n",
    "    def forward(self, s,v):\n",
    "        \n",
    "        # split and take linear combinations\n",
    "        #s, v = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "        \n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "        \n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "        \n",
    "        v_u = v.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        v_ut = torch.transpose(v_u,1,2)\n",
    "        U = torch.transpose(self.denseU(v_ut),1,2)\n",
    "        V = torch.transpose(self.denseV(v_ut),1,2)\n",
    "        \n",
    "        \n",
    "        # form the dot product\n",
    "        UV =  torch.einsum('ijk,ijk->ij',U,V) \n",
    "        \n",
    "        # s_j channel\n",
    "        nV = torch.norm(V, dim=-1)\n",
    "\n",
    "        s_u = torch.cat([s, nV], dim=-1)\n",
    "        s_u = self.lin_up(s_u) \n",
    "        s_u = Func.silu(s_u)\n",
    "        s_u = self.lin2(s_u)\n",
    "        #s_u = Func.silu(s_u)\n",
    "        \n",
    "        # final split\n",
    "        top, middle, bottom = torch.tensor_split(s_u,3,dim=-1)\n",
    "        \n",
    "        # outputs\n",
    "        dvu = torch.einsum('ijk,ij->ijk',v_u,top) \n",
    "        dsu = middle*UV + bottom \n",
    "        \n",
    "        #update = torch.cat((dsu,dvu.flatten(-2)), dim=-1)\n",
    "        \n",
    "        return dsu, dvu.reshape(-1, int(flat_shape_v/3), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain model equivariant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "from torch.nn import Linear\n",
    "\n",
    "class PaiNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feat,\n",
    "        out_channels,\n",
    "        num_nodes,\n",
    "        cut_off=5.0,\n",
    "        n_rbf=20,\n",
    "        num_interactions=3,\n",
    "    ):\n",
    "        super(PaiNN, self).__init__()\n",
    "        \"\"\"PyG implementation of PaiNN network of Schütt et. al. Supports two arrays\n",
    "           stored at the nodes of shape (num_nodes,num_feat,1) and (num_nodes, num_feat,3). For this\n",
    "           representation to be compatible with PyG, the arrays are flattened and concatenated.\n",
    "           Important to note is that the out_channels must match number of features\"\"\"\n",
    "\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cut_off = cut_off\n",
    "        self.n_rbf = n_rbf\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_feat = num_feat\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(num_feat, num_feat)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        self.list_message = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN(num_feat, out_channels, num_nodes, cut_off, n_rbf)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.list_update = nn.ModuleList(\n",
    "            [\n",
    "                UpdatePaiNN(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, s, v, edge_index, edge_attr):\n",
    "\n",
    "        for i in range(self.num_interactions):\n",
    "\n",
    "            s_temp, v_temp = self.list_message[i](s, v, edge_index, edge_attr)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "            s_temp, v_temp = self.list_update[i](s, v)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "\n",
    "        s = self.lin(s)\n",
    "        s = self.silu(s)\n",
    "        s = self.lin(s)\n",
    "\n",
    "        return s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain model non-equivariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PaiNNElecNuc(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feat,\n",
    "        out_channels,\n",
    "        num_nodes,\n",
    "        cut_off=5.0,\n",
    "        n_rbf=20,\n",
    "        num_interactions=3,\n",
    "    ):\n",
    "        super(PaiNNElecNuc, self).__init__()\n",
    "        \"\"\"PyG implementation of PaiNN network of Schütt et. al. Supports two arrays\n",
    "           stored at the nodes of shape (num_nodes,num_feat,1) and (num_nodes, num_feat,3). For this\n",
    "           representation to be compatible with PyG, the arrays are flattened and concatenated.\n",
    "           Important to note is that the out_channels must match number of features\"\"\"\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cut_off = cut_off\n",
    "        self.n_rbf = n_rbf\n",
    "        self.linear = Linear(num_feat, num_feat)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        self.list_message = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN(num_feat, out_channels, num_nodes, cut_off, n_rbf)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.list_update = nn.ModuleList(\n",
    "            [\n",
    "                UpdatePaiNN(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.list_message_NE = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN_NE(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, s, v, s_nuc, v_nuc, edge_index, edge_attr, edge_index_nuc, edge_attr_nuc\n",
    "    ):\n",
    "\n",
    "        for i in range(self.num_interactions):\n",
    "\n",
    "            s_temp, v_temp = self.list_message[i](s, v, edge_index, edge_attr)\n",
    "            s_temp_NE, v_temp_NE = self.list_message_NE[i](\n",
    "                s, v, s_nuc, v_nuc, edge_index_nuc, edge_attr_nuc\n",
    "            )\n",
    "\n",
    "            s, v = s_temp + s + s_temp_NE, v_temp + v + v_temp_NE\n",
    "            s_temp, v_temp = self.list_update[i](s, v)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "\n",
    "        s = self.linear(s)\n",
    "        s = self.silu(s)\n",
    "        s = self.linear(s)\n",
    "\n",
    "        return s, v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of model (GPT currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Assuming you have a DataLoader for your training set and the PaiNNElecNuc model\n",
    "train_loader = ...\n",
    "model = PaiNNElecNuc(num_feat=..., out_channels=..., num_nodes=..., cut_off=..., n_rbf=..., num_interactions=...)\n",
    "\n",
    "# Set the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over batches in the training DataLoader\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Extract input features from the data (adjust this based on your actual data structure)\n",
    "        s = data.s  # Replace with the actual attribute names from your dataset\n",
    "        v = data.v\n",
    "        s_nuc = data.s_nuc\n",
    "        v_nuc = data.v_nuc\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        edge_index_nuc = data.edge_index_nuc\n",
    "        edge_attr_nuc = data.edge_attr_nuc\n",
    "\n",
    "        # Forward pass\n",
    "        output_s, output_v = model(s, v, s_nuc, v_nuc, edge_index, edge_attr, edge_index_nuc, edge_attr_nuc)\n",
    "\n",
    "        # Compute the loss\n",
    "        target_s = data.target_s  # Replace with the actual target names from your dataset\n",
    "        target_v = data.target_v\n",
    "        loss_s = criterion(output_s, target_s)\n",
    "        loss_v = criterion(output_v, target_v)\n",
    "        loss = loss_s + loss_v\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}')\n",
    "\n",
    "# Optionally, save the trained model\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
