{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset,\n",
    "    download_url,\n",
    "    extract_zip,\n",
    ")\n",
    "from torch_geometric.utils import one_hot, scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QM9 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM9(InMemoryDataset):\n",
    "    raw_url = ('https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/'\n",
    "                'molnet_publish/qm9.zip')\n",
    "    raw_url2 = 'https://ndownloader.figshare.com/files/3195404'\n",
    "    processed_url = 'https://data.pyg.org/datasets/qm9_v3.zip'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "    ):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter,\n",
    "                        force_reload=force_reload)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    def mean(self, target: int) -> float:\n",
    "        y = torch.cat([self.get(i).y for i in range(len(self))], dim=0)\n",
    "        return float(y[:, target].mean())\n",
    "\n",
    "    def std(self, target: int) -> float:\n",
    "        y = torch.cat([self.get(i).y for i in range(len(self))], dim=0)\n",
    "        return float(y[:, target].std())\n",
    "\n",
    "    def atomref(self, target) -> Optional[torch.Tensor]:\n",
    "        if target in atomrefs:\n",
    "            out = torch.zeros(100)\n",
    "            out[torch.tensor([1, 6, 7, 8, 9])] = torch.tensor(atomrefs[target])\n",
    "            return out.view(-1, 1)\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        try:\n",
    "            import rdkit  # noqa\n",
    "            return ['gdb9.sdf', 'gdb9.sdf.csv', 'uncharacterized.txt']\n",
    "        except ImportError:\n",
    "            return ['qm9_v3.pt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data_v3.pt'\n",
    "\n",
    "    def download(self):\n",
    "        try:\n",
    "            import rdkit  # noqa\n",
    "            file_path = download_url(self.raw_url, self.raw_dir)\n",
    "            extract_zip(file_path, self.raw_dir)\n",
    "            os.unlink(file_path)\n",
    "\n",
    "            file_path = download_url(self.raw_url2, self.raw_dir)\n",
    "            os.rename(osp.join(self.raw_dir, '3195404'),\n",
    "                    osp.join(self.raw_dir, 'uncharacterized.txt'))\n",
    "        except ImportError:\n",
    "            path = download_url(self.processed_url, self.raw_dir)\n",
    "            extract_zip(path, self.raw_dir)\n",
    "            os.unlink(path)\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            import rdkit\n",
    "            from rdkit import Chem, RDLogger\n",
    "            from rdkit.Chem.rdchem import BondType as BT\n",
    "            from rdkit.Chem.rdchem import HybridizationType\n",
    "            RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "        except ImportError:\n",
    "            rdkit = None\n",
    "\n",
    "        if rdkit is None:\n",
    "            print((\"Using a pre-processed version of the dataset. Please \"\n",
    "                \"install 'rdkit' to alternatively process the raw data.\"),\n",
    "                file=sys.stderr)\n",
    "\n",
    "            data_list = torch.load(self.raw_paths[0])\n",
    "            data_list = [Data(**data_dict) for data_dict in data_list]\n",
    "\n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "            self.save(data_list, self.processed_paths[0])\n",
    "            return\n",
    "\n",
    "        types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\n",
    "        bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
    "\n",
    "        with open(self.raw_paths[1], 'r') as f:\n",
    "            target = f.read().split('\\n')[1:-1]\n",
    "            target = [[float(x) for x in line.split(',')[1:20]]\n",
    "                    for line in target]\n",
    "            target = torch.tensor(target, dtype=torch.float)\n",
    "            target = torch.cat([target[:, 3:], target[:, :3]], dim=-1)\n",
    "            target = target * conversion.view(1, -1)\n",
    "\n",
    "        with open(self.raw_paths[2], 'r') as f:\n",
    "            skip = [int(x.split()[0]) - 1 for x in f.read().split('\\n')[9:-2]]\n",
    "\n",
    "        suppl = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False,\n",
    "                                sanitize=False)\n",
    "\n",
    "        data_list = []\n",
    "        for i, mol in enumerate(tqdm(suppl)):\n",
    "            if i in skip:\n",
    "                continue\n",
    "\n",
    "            N = mol.GetNumAtoms()\n",
    "\n",
    "            conf = mol.GetConformer()\n",
    "            pos = conf.GetPositions()\n",
    "            pos = torch.tensor(pos, dtype=torch.float)\n",
    "\n",
    "            type_idx = []\n",
    "            atomic_number = []\n",
    "            aromatic = []\n",
    "            sp = []\n",
    "            sp2 = []\n",
    "            sp3 = []\n",
    "            num_hs = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                type_idx.append(types[atom.GetSymbol()])\n",
    "                atomic_number.append(atom.GetAtomicNum())\n",
    "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
    "                hybridization = atom.GetHybridization()\n",
    "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
    "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
    "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
    "\n",
    "            z = torch.tensor(atomic_number, dtype=torch.long)\n",
    "\n",
    "            row, col, edge_type = [], [], []\n",
    "            for bond in mol.GetBonds():\n",
    "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "                row += [start, end]\n",
    "                col += [end, start]\n",
    "                edge_type += 2 * [bonds[bond.GetBondType()]]\n",
    "\n",
    "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "            edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
    "            edge_attr = one_hot(edge_type, num_classes=len(bonds))\n",
    "\n",
    "            perm = (edge_index[0] * N + edge_index[1]).argsort()\n",
    "            edge_index = edge_index[:, perm]\n",
    "            edge_type = edge_type[perm]\n",
    "            edge_attr = edge_attr[perm]\n",
    "\n",
    "            row, col = edge_index\n",
    "            hs = (z == 1).to(torch.float)\n",
    "            num_hs = scatter(hs[row], col, dim_size=N, reduce='sum').tolist()\n",
    "\n",
    "            x1 = one_hot(torch.tensor(type_idx), num_classes=len(types))\n",
    "            x2 = torch.tensor([atomic_number, aromatic, sp, sp2, sp3, num_hs],\n",
    "                            dtype=torch.float).t().contiguous()\n",
    "            x = torch.cat([x1, x2], dim=-1)\n",
    "\n",
    "            y = target[i].unsqueeze(0)\n",
    "            name = mol.GetProp('_Name')\n",
    "            smiles = Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "\n",
    "            data = Data(\n",
    "                x=x,\n",
    "                z=z,\n",
    "                pos=pos,\n",
    "                edge_index=edge_index,\n",
    "                smiles=smiles,\n",
    "                edge_attr=edge_attr,\n",
    "                y=y,\n",
    "                name=name,\n",
    "                idx=i,\n",
    "            )\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data using QM9 data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecules in the training set: 1000\n",
      "Number of molecules in the test set: 1000\n",
      "Number of molecules in the validation set: 1000\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "\n",
    "# Set the root directory where the dataset will be stored\n",
    "root = \"your/root/directory\"\n",
    "\n",
    "# Instantiate the QM9 dataset\n",
    "dataset = QM9(root)\n",
    "\n",
    "# Limit the dataset to the first 3000 molecules\n",
    "dataset = dataset[:3000]\n",
    "\n",
    "# Split the dataset into training, testing, and validation sets\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [1000, 1000, 1000], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Print the number of molecules in each set\n",
    "print(f\"Number of molecules in the training set: {len(train_dataset)}\")\n",
    "print(f\"Number of molecules in the test set: {len(test_dataset)}\")\n",
    "print(f\"Number of molecules in the validation set: {len(val_dataset)}\")\n",
    "\n",
    "#Extract attributes from data\n",
    "s = dataset.z\n",
    "pos = dataset.pos\n",
    "edge_index = dataset.edge_index\n",
    "edge_attr = dataset.edge_attr\n",
    "y = dataset.y\n",
    "v = torch.tensor(128)\n",
    "num_feat = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing dataframe for first molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of the first molecule:\n",
      "x: tensor([[0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 4.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "z: tensor([6, 1, 1, 1, 1])\n",
      "edge_index: tensor([[0, 0, 0, 0, 1, 2, 3, 4],\n",
      "        [1, 2, 3, 4, 0, 0, 0, 0]])\n",
      "edge_attr: tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "y: tensor([[    0.0000,    13.2100,   -10.5499,     3.1865,    13.7363,    35.3641,\n",
      "             1.2177, -1101.4878, -1101.4098, -1101.3840, -1102.0229,     6.4690,\n",
      "           -17.1722,   -17.2868,   -17.3897,   -16.1519,   157.7118,   157.7100,\n",
      "           157.7070]])\n",
      "pos: tensor([[-1.2700e-02,  1.0858e+00,  8.0000e-03],\n",
      "        [ 2.2000e-03, -6.0000e-03,  2.0000e-03],\n",
      "        [ 1.0117e+00,  1.4638e+00,  3.0000e-04],\n",
      "        [-5.4080e-01,  1.4475e+00, -8.7660e-01],\n",
      "        [-5.2380e-01,  1.4379e+00,  9.0640e-01]])\n"
     ]
    }
   ],
   "source": [
    "# Extract attributes from the first molecule in the dataset\n",
    "first_molecule = dataset[0]\n",
    "x_first_molecule = first_molecule.x\n",
    "z_first_molecule = first_molecule.z\n",
    "edge_index_first_molecule = first_molecule.edge_index\n",
    "edge_attr_first_molecule = first_molecule.edge_attr\n",
    "y_first_molecule = first_molecule.y\n",
    "pos_first_molecule = first_molecule.pos\n",
    "\n",
    "# Print the attributes\n",
    "print(\"Attributes of the first molecule:\")\n",
    "print(f\"x: {x_first_molecule}\")\n",
    "print(f\"z: {z_first_molecule}\")\n",
    "print(f\"edge_index: {edge_index_first_molecule}\")\n",
    "print(f\"edge_attr: {edge_attr_first_molecule}\")\n",
    "print(f\"y: {y_first_molecule}\")\n",
    "print(f\"pos: {pos_first_molecule}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for PAINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.data import Batch, Data, DataLoader\n",
    "from torch_geometric.nn import radius, radius_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F_cut & RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineCutoff(torch.nn.Module):\n",
    "    def __init__(self, cutoff=5.0):\n",
    "        super(CosineCutoff, self).__init__()\n",
    "        # self.register_buffer(\"cutoff\", torch.FloatTensor([cutoff]))\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def forward(self, distances):\n",
    "        \"\"\"Compute cutoff.\n",
    "\n",
    "        Args:\n",
    "            distances (torch.Tensor): values of interatomic distances.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: values of cutoff function.\n",
    "\n",
    "        \"\"\"\n",
    "        # Compute values of cutoff function\n",
    "        cutoffs = 0.5 * (torch.cos(distances * np.pi / self.cutoff) + 1.0)\n",
    "        # Remove contributions beyond the cutoff radius\n",
    "        cutoffs *= (distances < self.cutoff).float()\n",
    "        return cutoffs\n",
    "\n",
    "\n",
    "class BesselBasis(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Sine for radial basis expansion with coulomb decay. (0th order Bessel from DimeNet)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cutoff=5.0, n_rbf=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cutoff: radial cutoff\n",
    "            n_rbf: number of basis functions.\n",
    "        \"\"\"\n",
    "        super(BesselBasis, self).__init__()\n",
    "        # compute offset and width of Gaussian functions\n",
    "        freqs = torch.arange(1, n_rbf + 1) * math.pi / cutoff\n",
    "        self.register_buffer(\"freqs\", freqs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = torch.norm(inputs, p=2, dim=1)\n",
    "        a = self.freqs\n",
    "        ax = torch.outer(inputs, a)\n",
    "        sinax = torch.sin(ax)\n",
    "\n",
    "        norm = torch.where(inputs == 0, torch.tensor(1.0, device=inputs.device), inputs)\n",
    "        y = sinax / norm[:, None]\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class MessagePassPaiNN(MessagePassing):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20):\n",
    "        super(MessagePassPaiNN, self).__init__(aggr=\"add\")\n",
    "\n",
    "        self.lin1 = Linear(num_feat, out_channels)\n",
    "        self.lin2 = Linear(out_channels, 3 * out_channels)\n",
    "        self.lin_rbf = Linear(n_rbf, 3 * out_channels)\n",
    "        self.silu = Func.silu\n",
    "        self.embedding = nn.Embedding(100, num_feat)\n",
    "\n",
    "        self.RBF = BesselBasis(cut_off, n_rbf)\n",
    "        self.f_cut = CosineCutoff(cut_off)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_feat = num_feat\n",
    "\n",
    "    def forward(self, s, v, edge_index, edge_attr):\n",
    "        s = self.embedding(s)\n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "\n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "\n",
    "        x = torch.cat([s, v], dim=-1)\n",
    "\n",
    "        x = self.propagate(\n",
    "            edge_index,\n",
    "            x=x,\n",
    "            edge_attr=edge_attr,\n",
    "            flat_shape_s=flat_shape_s,\n",
    "            flat_shape_v=flat_shape_v,\n",
    "        )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j, edge_attr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        # Split Input into s_j and v_j\n",
    "        s_j, v_j = torch.split(x_j, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        # r_ij channel\n",
    "        rbf = self.RBF(edge_attr)\n",
    "        ch1 = self.lin_rbf(rbf)\n",
    "        cut = self.f_cut(edge_attr.norm(dim=-1))\n",
    "        W = torch.einsum(\"ij,i->ij\", ch1, cut)  # ch1 * f_cut\n",
    "\n",
    "        # s_j channel\n",
    "        phi = self.lin1(s_j)\n",
    "        phi = self.silu(phi)\n",
    "        phi = self.lin2(phi)\n",
    "\n",
    "        # Split\n",
    "\n",
    "        left, dsm, right = torch.split(phi * W, self.num_feat, dim=-1)\n",
    "\n",
    "        # v_j channel\n",
    "        normalized = Func.normalize(edge_attr, p=2, dim=1)\n",
    "        v_j = v_j.reshape(-1, int(flat_shape_v / 3), 3)\n",
    "        hadamard_right = torch.einsum(\"ij,ik->ijk\", right, normalized)\n",
    "        hadamard_left = torch.einsum(\"ijk,ij->ijk\", v_j, left)\n",
    "        dvm = hadamard_left + hadamard_right\n",
    "\n",
    "        # Prepare vector for update\n",
    "        x_j = torch.cat((dsm, dvm.flatten(-2)), dim=-1)\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, out_aggr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        s_j, v_j = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        return s_j, v_j.reshape(-1, int(flat_shape_v / 3), 3)\n",
    "\n",
    "\n",
    "class MessagePassPaiNN_NE(MessagePassing):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20):\n",
    "        super(MessagePassPaiNN_NE, self).__init__(aggr=\"add\")\n",
    "\n",
    "        self.lin1 = Linear(num_feat, out_channels)\n",
    "        self.lin2 = Linear(out_channels, 3 * out_channels)\n",
    "        self.lin_rbf = Linear(n_rbf, 3 * out_channels)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        # self.prepare = Prepare_Message_Vector(num_nodes)\n",
    "        self.RBF = BesselBasis(cut_off, n_rbf)\n",
    "        self.f_cut = CosineCutoff(cut_off)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_feat = num_feat\n",
    "\n",
    "    def forward(self, s, v, s_nuc, v_nuc, edge_index, edge_attr):\n",
    "\n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "\n",
    "        s_nuc = s_nuc.flatten(-1)\n",
    "        v_nuc = v_nuc.flatten(-2)\n",
    "\n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "\n",
    "        n_nuc = s_nuc.shape[0]\n",
    "        n_elec = s.shape[0]\n",
    "\n",
    "        x_p = torch.cat([s_nuc, v_nuc], dim=-1)  # nuclei\n",
    "        x = torch.cat([s, v], dim=-1)  # electrons\n",
    "\n",
    "        x = self.propagate(\n",
    "            edge_index,\n",
    "            x=(x_p, x),\n",
    "            edge_attr=edge_attr,\n",
    "            flat_shape_s=flat_shape_s,\n",
    "            flat_shape_v=flat_shape_v,\n",
    "            size=(n_nuc, n_elec),\n",
    "        )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j, edge_attr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        # Split Input into s_j and v_j\n",
    "        s_j, v_j = torch.split(x_j, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "        # _, v_i = torch.split(x_i, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        # r_ij channel\n",
    "        rbf = self.RBF(edge_attr)\n",
    "        ch1 = self.lin_rbf(rbf)\n",
    "        cut = self.f_cut(edge_attr.norm(dim=-1))\n",
    "        W = torch.einsum(\"ij,i->ij\", ch1, cut)  # ch1 * f_cut\n",
    "\n",
    "        # s_j channel\n",
    "        phi = self.lin1(s_j)\n",
    "        phi = self.silu(phi)\n",
    "        phi = self.lin2(phi)\n",
    "\n",
    "        # Split\n",
    "        left, dsm, right = torch.split(phi * W, self.num_feat, dim=-1)\n",
    "\n",
    "        # v_j channel\n",
    "        normalized = Func.normalize(edge_attr, p=2, dim=1)\n",
    "\n",
    "        v_j = v_j.reshape(-1, int(flat_shape_v / 3), 3)\n",
    "        # v_i = v_i.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        # print(v_j - v_i)\n",
    "        hadamard_right = torch.einsum(\"ij,ik->ijk\", right, normalized)\n",
    "        hadamard_left = torch.einsum(\"ijk,ij->ijk\", v_j, left)\n",
    "        dvm = hadamard_left + hadamard_right\n",
    "\n",
    "        # Prepare vector for update\n",
    "        x_j = torch.cat((dsm, dvm.flatten(-2)), dim=-1)\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, out_aggr, flat_shape_s, flat_shape_v):\n",
    "\n",
    "        s_j, v_j = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "\n",
    "        return s_j, v_j.reshape(-1, int(flat_shape_v / 3), 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatePaiNN(torch.nn.Module):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes):\n",
    "        super(UpdatePaiNN, self).__init__() \n",
    "        \n",
    "        self.lin_up = Linear(2*num_feat, out_channels) \n",
    "        self.denseU = Linear(num_feat,out_channels, bias = False) \n",
    "        self.denseV = Linear(num_feat,out_channels, bias = False) \n",
    "        self.lin2 = Linear(out_channels, 3*out_channels) \n",
    "        self.silu = Func.silu\n",
    "        \n",
    "        \n",
    "    def forward(self, s,v):\n",
    "        \n",
    "        # split and take linear combinations\n",
    "        #s, v = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "        \n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "        \n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "        \n",
    "        v_u = v.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        v_ut = torch.transpose(v_u,1,2)\n",
    "        U = torch.transpose(self.denseU(v_ut),1,2)\n",
    "        V = torch.transpose(self.denseV(v_ut),1,2)\n",
    "        \n",
    "        \n",
    "        # form the dot product\n",
    "        UV =  torch.einsum('ijk,ijk->ij',U,V) \n",
    "        \n",
    "        # s_j channel\n",
    "        nV = torch.norm(V, dim=-1)\n",
    "\n",
    "        s_u = torch.cat([s, nV], dim=-1)\n",
    "        s_u = self.lin_up(s_u) \n",
    "        s_u = Func.silu(s_u)\n",
    "        s_u = self.lin2(s_u)\n",
    "        #s_u = Func.silu(s_u)\n",
    "        \n",
    "        # final split\n",
    "        top, middle, bottom = torch.tensor_split(s_u,3,dim=-1)\n",
    "        \n",
    "        # outputs\n",
    "        dvu = torch.einsum('ijk,ij->ijk',v_u,top) \n",
    "        dsu = middle*UV + bottom \n",
    "        \n",
    "        #update = torch.cat((dsu,dvu.flatten(-2)), dim=-1)\n",
    "        \n",
    "        return dsu, dvu.reshape(-1, int(flat_shape_v/3), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain model equivariant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "from torch.nn import Linear\n",
    "\n",
    "class PaiNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feat,\n",
    "        out_channels,\n",
    "        num_nodes,\n",
    "        cut_off=5.0,\n",
    "        n_rbf=20,\n",
    "        num_interactions=3,\n",
    "    ):\n",
    "        super(PaiNN, self).__init__()\n",
    "        \"\"\"PyG implementation of PaiNN network of Schütt et. al. Supports two arrays\n",
    "           stored at the nodes of shape (num_nodes,num_feat,1) and (num_nodes, num_feat,3). For this\n",
    "           representation to be compatible with PyG, the arrays are flattened and concatenated.\n",
    "           Important to note is that the out_channels must match number of features\"\"\"\n",
    "\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cut_off = cut_off\n",
    "        self.n_rbf = n_rbf\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_feat = num_feat\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(num_feat, num_feat)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        self.list_message = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN(num_feat, out_channels, num_nodes, cut_off, n_rbf)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.list_update = nn.ModuleList(\n",
    "            [\n",
    "                UpdatePaiNN(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, s, v, edge_index, edge_attr):\n",
    "\n",
    "        for i in range(self.num_interactions):\n",
    "\n",
    "            s_temp, v_temp = self.list_message[i](s, v, edge_index, edge_attr)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "            s_temp, v_temp = self.list_update[i](s, v)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "\n",
    "        s = self.lin(s)\n",
    "        s = self.silu(s)\n",
    "        s = self.lin(s)\n",
    "\n",
    "        return s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pain model non-equivariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PaiNNElecNuc(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feat,\n",
    "        out_channels,\n",
    "        num_nodes,\n",
    "        cut_off=5.0,\n",
    "        n_rbf=20,\n",
    "        num_interactions=3,\n",
    "    ):\n",
    "        super(PaiNNElecNuc, self).__init__()\n",
    "        \"\"\"PyG implementation of PaiNN network of Schütt et. al. Supports two arrays\n",
    "           stored at the nodes of shape (num_nodes,num_feat,1) and (num_nodes, num_feat,3). For this\n",
    "           representation to be compatible with PyG, the arrays are flattened and concatenated.\n",
    "           Important to note is that the out_channels must match number of features\"\"\"\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cut_off = cut_off\n",
    "        self.n_rbf = n_rbf\n",
    "        self.linear = Linear(num_feat, num_feat)\n",
    "        self.silu = Func.silu\n",
    "\n",
    "        self.list_message = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN(num_feat, out_channels, num_nodes, cut_off, n_rbf)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.list_update = nn.ModuleList(\n",
    "            [\n",
    "                UpdatePaiNN(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.list_message_NE = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN_NE(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, s, v, s_nuc, v_nuc, edge_index, edge_attr, edge_index_nuc, edge_attr_nuc\n",
    "    ):\n",
    "\n",
    "        for i in range(self.num_interactions):\n",
    "\n",
    "            s_temp, v_temp = self.list_message[i](s, v, edge_index, edge_attr)\n",
    "            s_temp_NE, v_temp_NE = self.list_message_NE[i](\n",
    "                s, v, s_nuc, v_nuc, edge_index_nuc, edge_attr_nuc\n",
    "            )\n",
    "\n",
    "            s, v = s_temp + s + s_temp_NE, v_temp + v + v_temp_NE\n",
    "            s_temp, v_temp = self.list_update[i](s, v)\n",
    "            s, v = s_temp + s, v_temp + v\n",
    "\n",
    "        s = self.linear(s)\n",
    "        s = self.silu(s)\n",
    "        s = self.linear(s)\n",
    "\n",
    "        return s, v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of model (GPT currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Epoch 1/10:   0%|          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\QM9_2.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m y \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# Assuming y is the target\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m output, _ \u001b[39m=\u001b[39m model(s, v, s, v, edge_index, edge_attr, edge_index, edge_attr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Compute the loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\QM9_2.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mself\u001b[39m, s, v, s_nuc, v_nuc, edge_index, edge_attr, edge_index_nuc, edge_attr_nuc\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m ):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_interactions):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m         s_temp, v_temp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlist_message[i](s, v, edge_index, edge_attr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         s_temp_NE, v_temp_NE \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_message_NE[i](\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m             s, v, s_nuc, v_nuc, edge_index_nuc, edge_attr_nuc\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         s, v \u001b[39m=\u001b[39m s_temp \u001b[39m+\u001b[39m s \u001b[39m+\u001b[39m s_temp_NE, v_temp \u001b[39m+\u001b[39m v \u001b[39m+\u001b[39m v_temp_NE\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\notebooks\\QM9_2.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(s)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mflatten(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39;49mflatten(\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m flat_shape_v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/notebooks/QM9_2.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m flat_shape_s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import QM9\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the root directory where the dataset will be stored\n",
    "root = \"your/root/directory\"\n",
    "\n",
    "# Instantiate the QM9 dataset\n",
    "dataset = QM9(root)\n",
    "\n",
    "# Limit the dataset to the first 3000 molecules\n",
    "dataset = dataset[:3000]\n",
    "\n",
    "# Split the dataset into training, testing, and validation sets\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [1000, 1000, 1000], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Define the DataLoader for training, testing, and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Instantiate your PaiNNElecNuc model\n",
    "num_feat = 128\n",
    "out_channels = 128  # This should match num_feat\n",
    "num_nodes = 1  # Update this based on your actual dataset\n",
    "model = PaiNNElecNuc(num_feat, out_channels, num_nodes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for data in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Extract data attributes\n",
    "        s = data.z\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        y = data.y.view(-1, 1)  # Assuming y is the target\n",
    "        \n",
    "        # Forward pass\n",
    "        output, _ = model(s, v, s, v, edge_index, edge_attr, edge_index, edge_attr)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss}\")\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc='Testing'):\n",
    "        s = data.z\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        predictions, _ = model(s, v, s, v, edge_index, edge_attr, edge_index, edge_attr)\n",
    "        \n",
    "        all_predictions.append(predictions.numpy())\n",
    "        all_targets.append(data.y.numpy())\n",
    "\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "\n",
    "# Calculate and print the Mean Squared Error on the test set\n",
    "mse = mean_squared_error(all_targets, all_predictions)\n",
    "print(f\"Mean Squared Error on the test set: {mse}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
