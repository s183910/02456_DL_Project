{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from fetch_data import qm9_parse, qm9_fetch\n",
    "import dmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing record file, delete if you want to re-fetch\n"
     ]
    }
   ],
   "source": [
    "qm9_records = qm9_fetch()\n",
    "\n",
    "data = qm9_parse(qm9_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(5,), dtype=int64, numpy=array([6, 1, 1, 1, 1], dtype=int64)>, <tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
      "array([[-1.2698136e-02,  1.0858041e+00,  8.0009960e-03, -5.3568900e-01],\n",
      "       [ 2.1504159e-03, -6.0313176e-03,  1.9761203e-03,  1.3392100e-01],\n",
      "       [ 1.0117308e+00,  1.4637512e+00,  2.7657481e-04,  1.3392200e-01],\n",
      "       [-5.4081506e-01,  1.4475266e+00, -8.7664372e-01,  1.3392299e-01],\n",
      "       [-5.2381361e-01,  1.4379326e+00,  9.0639728e-01,  1.3392299e-01]],\n",
      "      dtype=float32)>), <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([ 1.0000000e+00,  1.5771181e+02,  1.5770998e+02,  1.5770699e+02,\n",
      "        0.0000000e+00,  1.3210000e+01, -3.8769999e-01,  1.1710000e-01,\n",
      "        5.0480002e-01,  3.5364101e+01,  4.4748999e-02, -4.0478931e+01,\n",
      "       -4.0476063e+01, -4.0475117e+01, -4.0498596e+01,  6.4689999e+00],\n",
      "      dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(5,), dtype=int64, numpy=array([6, 1, 1, 1, 1], dtype=int64)>, <tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
      "array([[-1.2698136e-02,  1.0858041e+00,  8.0009960e-03, -5.3568900e-01],\n",
      "       [ 2.1504159e-03, -6.0313176e-03,  1.9761203e-03,  1.3392100e-01],\n",
      "       [ 1.0117308e+00,  1.4637512e+00,  2.7657481e-04,  1.3392200e-01],\n",
      "       [-5.4081506e-01,  1.4475266e+00, -8.7664372e-01,  1.3392299e-01],\n",
      "       [-5.2381361e-01,  1.4379326e+00,  9.0639728e-01,  1.3392299e-01]],\n",
      "      dtype=float32)>), <tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
      "array([ 1.0000000e+00,  1.5771181e+02,  1.5770998e+02,  1.5770699e+02,\n",
      "        0.0000000e+00,  1.3210000e+01, -3.8769999e-01,  1.1710000e-01,\n",
      "        5.0480002e-01,  3.5364101e+01,  4.4748999e-02, -4.0478931e+01,\n",
      "       -4.0476063e+01, -4.0475117e+01, -4.0498596e+01,  6.4689999e+00],\n",
      "      dtype=float32)>)\n",
      "Embedded Atomic Numbers:\n",
      " tensor([[-0.1413, -1.1223,  1.2316,  0.5507, -0.0244,  2.0424,  0.4475,  0.9750,\n",
      "         -1.5587, -0.3967, -0.1151, -0.1103, -1.2198,  0.6026, -1.3169, -1.4679,\n",
      "          0.3986,  1.8078,  1.8197, -0.7708, -1.6229, -2.4519, -0.6429,  1.1461,\n",
      "          0.5933, -0.0493,  0.6421,  0.3569, -0.3449,  0.2288,  0.5650, -0.1983,\n",
      "          0.2077,  0.1335,  0.9131,  0.7816, -0.5783, -0.5323, -0.5028,  1.1264,\n",
      "         -0.7413,  0.0516,  0.1615, -0.2885, -2.3391,  0.5065,  1.9370,  0.3119,\n",
      "          1.0446, -0.9906, -0.1815, -0.1488, -0.0556,  0.8874, -1.2257, -0.5513,\n",
      "          1.9085,  1.0337, -1.8863, -1.2300,  0.8960,  0.4929,  0.2938,  0.3205,\n",
      "         -0.3560,  0.7582,  0.4830, -1.1780, -0.8808, -0.1318,  0.7472, -1.0282,\n",
      "         -1.7308, -1.3092, -1.6020,  0.0353, -0.8367,  0.1572,  0.7194,  1.0816,\n",
      "          1.8550, -0.4205,  0.3254, -0.6593, -1.1087, -0.2535, -0.6776, -0.7259,\n",
      "         -0.0345,  0.2580, -0.2019, -1.8194, -0.1544, -0.6974,  0.8972,  0.8634,\n",
      "          0.0816,  1.4360, -0.6174, -2.0180,  1.1535, -0.1613,  0.7350,  0.7783,\n",
      "         -0.1087,  0.3218,  0.2550, -1.0976,  0.0845,  0.9131,  1.2956, -0.0737,\n",
      "         -0.5402,  0.8940,  0.7002,  0.7723,  0.0868, -0.5365, -0.1260, -0.1121,\n",
      "         -0.0971,  0.1663, -0.6333, -1.5862, -0.7394, -0.8112,  0.5684,  0.2302],\n",
      "        [ 0.4359, -0.9567,  1.0562,  0.4116, -1.4307, -1.2521, -0.9057,  0.3538,\n",
      "          0.6593, -0.0299, -0.7557, -0.4147, -2.2270, -0.7946, -0.8824,  0.6905,\n",
      "          0.6431,  0.4831,  0.5500,  0.4254, -0.8313, -0.7346, -0.6135, -1.2175,\n",
      "         -0.5950,  0.8787, -1.6536,  0.3511,  0.8928,  1.9734, -0.4672,  0.0366,\n",
      "          0.0782, -0.6164, -0.0829, -1.3043, -1.0285, -1.0094, -1.3850, -0.3228,\n",
      "          1.5229,  1.0272,  0.2218,  0.7735,  2.2894, -0.1768, -1.0162,  1.3191,\n",
      "          1.3890, -0.6774,  1.5958, -0.9943,  0.8149, -0.4101, -1.4159, -0.2718,\n",
      "         -0.5804,  0.2755, -0.8441,  0.5236,  0.0749, -1.7415, -0.7628,  0.1727,\n",
      "          0.6106,  1.5903,  0.7270,  0.3283, -0.2400,  0.0979,  0.9319, -0.1930,\n",
      "         -1.4958,  2.1843,  1.2834,  1.1100,  1.0337, -0.0661, -0.0989,  0.5213,\n",
      "         -0.9063,  0.1014,  0.3233, -0.1098,  0.7681, -0.5111,  1.5822,  1.0451,\n",
      "         -0.1113, -0.4081, -0.4416, -0.1092,  1.3953, -1.9486, -0.6931,  0.7525,\n",
      "          1.0267,  0.3307, -1.9172,  0.1352,  0.2205, -0.4340,  0.1920,  0.4180,\n",
      "          0.9160,  0.4317,  0.8289, -0.1682,  0.1887, -0.3945,  0.3586,  0.6685,\n",
      "          2.1453,  1.5764, -0.1542, -2.0638,  0.8284, -1.0054, -0.4528, -0.0288,\n",
      "          0.1098,  0.9218,  0.2552,  2.2380,  0.3069,  0.1052,  0.6424,  1.1100],\n",
      "        [ 0.4359, -0.9567,  1.0562,  0.4116, -1.4307, -1.2521, -0.9057,  0.3538,\n",
      "          0.6593, -0.0299, -0.7557, -0.4147, -2.2270, -0.7946, -0.8824,  0.6905,\n",
      "          0.6431,  0.4831,  0.5500,  0.4254, -0.8313, -0.7346, -0.6135, -1.2175,\n",
      "         -0.5950,  0.8787, -1.6536,  0.3511,  0.8928,  1.9734, -0.4672,  0.0366,\n",
      "          0.0782, -0.6164, -0.0829, -1.3043, -1.0285, -1.0094, -1.3850, -0.3228,\n",
      "          1.5229,  1.0272,  0.2218,  0.7735,  2.2894, -0.1768, -1.0162,  1.3191,\n",
      "          1.3890, -0.6774,  1.5958, -0.9943,  0.8149, -0.4101, -1.4159, -0.2718,\n",
      "         -0.5804,  0.2755, -0.8441,  0.5236,  0.0749, -1.7415, -0.7628,  0.1727,\n",
      "          0.6106,  1.5903,  0.7270,  0.3283, -0.2400,  0.0979,  0.9319, -0.1930,\n",
      "         -1.4958,  2.1843,  1.2834,  1.1100,  1.0337, -0.0661, -0.0989,  0.5213,\n",
      "         -0.9063,  0.1014,  0.3233, -0.1098,  0.7681, -0.5111,  1.5822,  1.0451,\n",
      "         -0.1113, -0.4081, -0.4416, -0.1092,  1.3953, -1.9486, -0.6931,  0.7525,\n",
      "          1.0267,  0.3307, -1.9172,  0.1352,  0.2205, -0.4340,  0.1920,  0.4180,\n",
      "          0.9160,  0.4317,  0.8289, -0.1682,  0.1887, -0.3945,  0.3586,  0.6685,\n",
      "          2.1453,  1.5764, -0.1542, -2.0638,  0.8284, -1.0054, -0.4528, -0.0288,\n",
      "          0.1098,  0.9218,  0.2552,  2.2380,  0.3069,  0.1052,  0.6424,  1.1100],\n",
      "        [ 0.4359, -0.9567,  1.0562,  0.4116, -1.4307, -1.2521, -0.9057,  0.3538,\n",
      "          0.6593, -0.0299, -0.7557, -0.4147, -2.2270, -0.7946, -0.8824,  0.6905,\n",
      "          0.6431,  0.4831,  0.5500,  0.4254, -0.8313, -0.7346, -0.6135, -1.2175,\n",
      "         -0.5950,  0.8787, -1.6536,  0.3511,  0.8928,  1.9734, -0.4672,  0.0366,\n",
      "          0.0782, -0.6164, -0.0829, -1.3043, -1.0285, -1.0094, -1.3850, -0.3228,\n",
      "          1.5229,  1.0272,  0.2218,  0.7735,  2.2894, -0.1768, -1.0162,  1.3191,\n",
      "          1.3890, -0.6774,  1.5958, -0.9943,  0.8149, -0.4101, -1.4159, -0.2718,\n",
      "         -0.5804,  0.2755, -0.8441,  0.5236,  0.0749, -1.7415, -0.7628,  0.1727,\n",
      "          0.6106,  1.5903,  0.7270,  0.3283, -0.2400,  0.0979,  0.9319, -0.1930,\n",
      "         -1.4958,  2.1843,  1.2834,  1.1100,  1.0337, -0.0661, -0.0989,  0.5213,\n",
      "         -0.9063,  0.1014,  0.3233, -0.1098,  0.7681, -0.5111,  1.5822,  1.0451,\n",
      "         -0.1113, -0.4081, -0.4416, -0.1092,  1.3953, -1.9486, -0.6931,  0.7525,\n",
      "          1.0267,  0.3307, -1.9172,  0.1352,  0.2205, -0.4340,  0.1920,  0.4180,\n",
      "          0.9160,  0.4317,  0.8289, -0.1682,  0.1887, -0.3945,  0.3586,  0.6685,\n",
      "          2.1453,  1.5764, -0.1542, -2.0638,  0.8284, -1.0054, -0.4528, -0.0288,\n",
      "          0.1098,  0.9218,  0.2552,  2.2380,  0.3069,  0.1052,  0.6424,  1.1100],\n",
      "        [ 0.4359, -0.9567,  1.0562,  0.4116, -1.4307, -1.2521, -0.9057,  0.3538,\n",
      "          0.6593, -0.0299, -0.7557, -0.4147, -2.2270, -0.7946, -0.8824,  0.6905,\n",
      "          0.6431,  0.4831,  0.5500,  0.4254, -0.8313, -0.7346, -0.6135, -1.2175,\n",
      "         -0.5950,  0.8787, -1.6536,  0.3511,  0.8928,  1.9734, -0.4672,  0.0366,\n",
      "          0.0782, -0.6164, -0.0829, -1.3043, -1.0285, -1.0094, -1.3850, -0.3228,\n",
      "          1.5229,  1.0272,  0.2218,  0.7735,  2.2894, -0.1768, -1.0162,  1.3191,\n",
      "          1.3890, -0.6774,  1.5958, -0.9943,  0.8149, -0.4101, -1.4159, -0.2718,\n",
      "         -0.5804,  0.2755, -0.8441,  0.5236,  0.0749, -1.7415, -0.7628,  0.1727,\n",
      "          0.6106,  1.5903,  0.7270,  0.3283, -0.2400,  0.0979,  0.9319, -0.1930,\n",
      "         -1.4958,  2.1843,  1.2834,  1.1100,  1.0337, -0.0661, -0.0989,  0.5213,\n",
      "         -0.9063,  0.1014,  0.3233, -0.1098,  0.7681, -0.5111,  1.5822,  1.0451,\n",
      "         -0.1113, -0.4081, -0.4416, -0.1092,  1.3953, -1.9486, -0.6931,  0.7525,\n",
      "          1.0267,  0.3307, -1.9172,  0.1352,  0.2205, -0.4340,  0.1920,  0.4180,\n",
      "          0.9160,  0.4317,  0.8289, -0.1682,  0.1887, -0.3945,  0.3586,  0.6685,\n",
      "          2.1453,  1.5764, -0.1542, -2.0638,  0.8284, -1.0054, -0.4528, -0.0288,\n",
      "          0.1098,  0.9218,  0.2552,  2.2380,  0.3069,  0.1052,  0.6424,  1.1100]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Coordinates:\n",
      " tensor([[-1.2698e-02,  1.0858e+00,  8.0010e-03],\n",
      "        [ 2.1504e-03, -6.0313e-03,  1.9761e-03],\n",
      "        [ 1.0117e+00,  1.4638e+00,  2.7657e-04],\n",
      "        [-5.4082e-01,  1.4475e+00, -8.7664e-01],\n",
      "        [-5.2381e-01,  1.4379e+00,  9.0640e-01]])\n",
      "Label: -40.475117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the embedding layer outside the loop\n",
    "embedding_layer = nn.Embedding(16, 128)\n",
    "\n",
    "def convert_record(d):\n",
    "    # break up record\n",
    "    (e, x), y = d\n",
    "    e = e.numpy()\n",
    "    x= x.numpy()\n",
    "    r= x[:,:3]\n",
    "    embedding= nn.Embedding(100,128,padding_idx=0)\n",
    "    e=torch.tensor(e)\n",
    "    e = embedding(e)\n",
    "    r =torch.tensor(r)\n",
    "    return(e,r),y.numpy()[13]\n",
    "\n",
    "for d in data:\n",
    "    print(d)\n",
    "    (e, x), y = convert_record(d)\n",
    "    print(\"Embedded Atomic Numbers:\\n\", e)\n",
    "    print(\"Coordinates:\\n\", x)\n",
    "    print(\"Label:\", y)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'schnetpack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vonge\\OneDrive\\Dokumenter\\GitHub\\02456_DL_Project\\src\\Network.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mschnetpack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperties\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mproperties\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mschnetpack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msnn\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/OneDrive/Dokumenter/GitHub/02456_DL_Project/src/Network.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mPaiNN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPaiNNInteraction\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPaiNNMixing\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'schnetpack'"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Dict, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import schnetpack.properties as properties\n",
    "import schnetpack.nn as snn\n",
    "\n",
    "__all__ = [\"PaiNN\", \"PaiNNInteraction\", \"PaiNNMixing\"]\n",
    "\n",
    "\n",
    "class PaiNNInteraction(nn.Module):\n",
    "    r\"\"\"PaiNN interaction block for modeling equivariant interactions of atomistic systems.\"\"\"\n",
    "\n",
    "    def __init__(self, n_atom_basis: int, activation: Callable):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_atom_basis: number of features to describe atomic environments.\n",
    "            activation: if None, no activation function is used.\n",
    "            epsilon: stability constant added in norm to prevent numerical instabilities\n",
    "        \"\"\"\n",
    "        super(PaiNNInteraction, self).__init__()\n",
    "        self.n_atom_basis = n_atom_basis\n",
    "\n",
    "        self.interatomic_context_net = nn.Sequential(\n",
    "            snn.Dense(n_atom_basis, n_atom_basis, activation=activation),\n",
    "            snn.Dense(n_atom_basis, 3 * n_atom_basis, activation=None),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        q: torch.Tensor,\n",
    "        mu: torch.Tensor,\n",
    "        Wij: torch.Tensor,\n",
    "        dir_ij: torch.Tensor,\n",
    "        idx_i: torch.Tensor,\n",
    "        idx_j: torch.Tensor,\n",
    "        n_atoms: int,\n",
    "    ):\n",
    "        \"\"\"Compute interaction output.\n",
    "\n",
    "        Args:\n",
    "            q: scalar input values\n",
    "            mu: vector input values\n",
    "            Wij: filter\n",
    "            idx_i: index of center atom i\n",
    "            idx_j: index of neighbors j\n",
    "\n",
    "        Returns:\n",
    "            atom features after interaction\n",
    "        \"\"\"\n",
    "        # inter-atomic\n",
    "        x = self.interatomic_context_net(q)\n",
    "        xj = x[idx_j]\n",
    "        muj = mu[idx_j]\n",
    "        x = Wij * xj\n",
    "\n",
    "        dq, dmuR, dmumu = torch.split(x, self.n_atom_basis, dim=-1)\n",
    "        dq = snn.scatter_add(dq, idx_i, dim_size=n_atoms)\n",
    "        dmu = dmuR * dir_ij[..., None] + dmumu * muj\n",
    "        dmu = snn.scatter_add(dmu, idx_i, dim_size=n_atoms)\n",
    "\n",
    "        q = q + dq\n",
    "        mu = mu + dmu\n",
    "\n",
    "        return q, mu\n",
    "\n",
    "\n",
    "class PaiNNMixing(nn.Module):\n",
    "    r\"\"\"PaiNN interaction block for mixing on atom features.\"\"\"\n",
    "\n",
    "    def __init__(self, n_atom_basis: int, activation: Callable, epsilon: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_atom_basis: number of features to describe atomic environments.\n",
    "            activation: if None, no activation function is used.\n",
    "            epsilon: stability constant added in norm to prevent numerical instabilities\n",
    "        \"\"\"\n",
    "        super(PaiNNMixing, self).__init__()\n",
    "        self.n_atom_basis = n_atom_basis\n",
    "\n",
    "        self.intraatomic_context_net = nn.Sequential(\n",
    "            snn.Dense(2 * n_atom_basis, n_atom_basis, activation=activation),\n",
    "            snn.Dense(n_atom_basis, 3 * n_atom_basis, activation=None),\n",
    "        )\n",
    "        self.mu_channel_mix = snn.Dense(\n",
    "            n_atom_basis, 2 * n_atom_basis, activation=None, bias=False\n",
    "        )\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, q: torch.Tensor, mu: torch.Tensor):\n",
    "        \"\"\"Compute intraatomic mixing.\n",
    "\n",
    "        Args:\n",
    "            q: scalar input values\n",
    "            mu: vector input values\n",
    "\n",
    "        Returns:\n",
    "            atom features after interaction\n",
    "        \"\"\"\n",
    "        ## intra-atomic\n",
    "        mu_mix = self.mu_channel_mix(mu)\n",
    "        mu_V, mu_W = torch.split(mu_mix, self.n_atom_basis, dim=-1)\n",
    "        mu_Vn = torch.sqrt(torch.sum(mu_V**2, dim=-2, keepdim=True) + self.epsilon)\n",
    "\n",
    "        ctx = torch.cat([q, mu_Vn], dim=-1)\n",
    "        x = self.intraatomic_context_net(ctx)\n",
    "\n",
    "        dq_intra, dmu_intra, dqmu_intra = torch.split(x, self.n_atom_basis, dim=-1)\n",
    "        dmu_intra = dmu_intra * mu_W\n",
    "\n",
    "        dqmu_intra = dqmu_intra * torch.sum(mu_V * mu_W, dim=1, keepdim=True)\n",
    "\n",
    "        q = q + dq_intra + dqmu_intra\n",
    "        mu = mu + dmu_intra\n",
    "        return q, mu\n",
    "\n",
    "\n",
    "class PaiNN(nn.Module):\n",
    "    \"\"\"PaiNN - polarizable interaction neural network\n",
    "\n",
    "    References:\n",
    "\n",
    "    .. [#painn1] Schütt, Unke, Gastegger:\n",
    "       Equivariant message passing for the prediction of tensorial properties and molecular spectra.\n",
    "       ICML 2021, http://proceedings.mlr.press/v139/schutt21a.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_atom_basis: int,\n",
    "        n_interactions: int,\n",
    "        radial_basis: nn.Module,\n",
    "        cutoff_fn: Optional[Callable] = None,\n",
    "        activation: Optional[Callable] = F.silu,\n",
    "        max_z: int = 100,\n",
    "        shared_interactions: bool = False,\n",
    "        shared_filters: bool = False,\n",
    "        epsilon: float = 1e-8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_atom_basis: number of features to describe atomic environments.\n",
    "                This determines the size of each embedding vector; i.e. embeddings_dim.\n",
    "            n_interactions: number of interaction blocks.\n",
    "            radial_basis: layer for expanding interatomic distances in a basis set\n",
    "            cutoff_fn: cutoff function\n",
    "            activation: activation function\n",
    "            shared_interactions: if True, share the weights across\n",
    "                interaction blocks.\n",
    "            shared_interactions: if True, share the weights across\n",
    "                filter-generating networks.\n",
    "            epsilon: stability constant added in norm to prevent numerical instabilities\n",
    "        \"\"\"\n",
    "        super(PaiNN, self).__init__()\n",
    "\n",
    "        self.n_atom_basis = n_atom_basis\n",
    "        self.n_interactions = n_interactions\n",
    "        self.cutoff_fn = cutoff_fn\n",
    "        self.cutoff = cutoff_fn.cutoff\n",
    "        self.radial_basis = radial_basis\n",
    "\n",
    "        self.embedding = nn.Embedding(max_z, n_atom_basis, padding_idx=0)\n",
    "\n",
    "        self.share_filters = shared_filters\n",
    "\n",
    "        if shared_filters:\n",
    "            self.filter_net = snn.Dense(\n",
    "                self.radial_basis.n_rbf, 3 * n_atom_basis, activation=None\n",
    "            )\n",
    "        else:\n",
    "            self.filter_net = snn.Dense(\n",
    "                self.radial_basis.n_rbf,\n",
    "                self.n_interactions * n_atom_basis * 3,\n",
    "                activation=None,\n",
    "            )\n",
    "\n",
    "        self.interactions = snn.replicate_module(\n",
    "            lambda: PaiNNInteraction(\n",
    "                n_atom_basis=self.n_atom_basis, activation=activation\n",
    "            ),\n",
    "            self.n_interactions,\n",
    "            shared_interactions,\n",
    "        )\n",
    "        self.mixing = snn.replicate_module(\n",
    "            lambda: PaiNNMixing(\n",
    "                n_atom_basis=self.n_atom_basis, activation=activation, epsilon=epsilon\n",
    "            ),\n",
    "            self.n_interactions,\n",
    "            shared_interactions,\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs: Dict[str, torch.Tensor]):\n",
    "        \"\"\"\n",
    "        Compute atomic representations/embeddings.\n",
    "\n",
    "        Args:\n",
    "            inputs (dict of torch.Tensor): SchNetPack dictionary of input tensors.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: atom-wise representation.\n",
    "            list of torch.Tensor: intermediate atom-wise representations, if\n",
    "            return_intermediate=True was used.\n",
    "        \"\"\"\n",
    "        # get tensors from input dictionary\n",
    "        atomic_numbers = inputs[properties.Z]\n",
    "        r_ij = inputs[properties.Rij]\n",
    "        idx_i = inputs[properties.idx_i]\n",
    "        idx_j = inputs[properties.idx_j]\n",
    "        n_atoms = atomic_numbers.shape[0]\n",
    "\n",
    "        # compute atom and pair features\n",
    "        d_ij = torch.norm(r_ij, dim=1, keepdim=True)\n",
    "        dir_ij = r_ij / d_ij\n",
    "        phi_ij = self.radial_basis(d_ij)\n",
    "        fcut = self.cutoff_fn(d_ij)\n",
    "\n",
    "        filters = self.filter_net(phi_ij) * fcut[..., None]\n",
    "        if self.share_filters:\n",
    "            filter_list = [filters] * self.n_interactions\n",
    "        else:\n",
    "            filter_list = torch.split(filters, 3 * self.n_atom_basis, dim=-1)\n",
    "\n",
    "        q = self.embedding(atomic_numbers)[:, None]\n",
    "        qs = q.shape\n",
    "        mu = torch.zeros((qs[0], 3, qs[2]), device=q.device)\n",
    "\n",
    "        for i, (interaction, mixing) in enumerate(zip(self.interactions, self.mixing)):\n",
    "            q, mu = interaction(q, mu, filter_list[i], dir_ij, idx_i, idx_j, n_atoms)\n",
    "            q, mu = mixing(q, mu)\n",
    "\n",
    "        q = q.squeeze(1)\n",
    "\n",
    "        inputs[\"scalar_representation\"] = q\n",
    "        inputs[\"vector_representation\"] = mu\n",
    "        return inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
